{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Fakenews_Detection_Mean Teacher_report_Dropouts.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chidipothuhareswathi/Fake-News-Detection/blob/master/Fakenews_Detection_Mean_Teacher_report_Dropouts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA482cSwxo5d",
        "colab_type": "text"
      },
      "source": [
        "As Mean squared difference between student and teacher model output distribution as consis-tency cost during training student model. Itâ€™s assumed that unlabeled data will be having truedistribution same as label data. By adding distribution difference while training, model tries toreduce the difference between student and teacher output distribution. The same distributiondifference has been implemented in VAT regularisation techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH_jzqgtaKZE",
        "colab_type": "text"
      },
      "source": [
        "# Declaring Libraries \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOCj2bQfiLH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#please install contractions \n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "# import contractions\n",
        "import string\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "import spacy\n",
        "import time\n",
        "import re\n",
        "\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim import utils \n",
        "from gensim.test.utils import get_tmpfile\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import en_core_web_sm\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# nlp = en_core_web_sm.load()\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('punkt')\n",
        "# porter=PorterStemmer()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlQXTXLez5Yl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9baf7f8d-e9a0-4180-fabb-ac20b9cdb199"
      },
      "source": [
        "import tensorflow as tf \n",
        "\n",
        "import tensorflow.keras as tfk\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#this is to enable eager execution\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "path = '/content/drive/My Drive/Colab Notebooks/LatestData_July'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Lpuz0gk_DW",
        "colab_type": "text"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7XLM4EqlCHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenization(x_train, x_test, x_unlabel, maxlen):\n",
        "\n",
        "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "    from tensorflow.keras.preprocessing import sequence\n",
        "    import numpy as np\n",
        "\n",
        "    # max_features = 20000\n",
        "    # maxlen = 100\n",
        "    # batch_size = 32\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ',\n",
        "                          char_level=False, oov_token=None, document_count=0)\n",
        "    full_article = np.hstack((x_train, x_test, x_unlabel))\n",
        "    tokenizer.fit_on_texts(full_article)\n",
        "    x_train_token = tokenizer.texts_to_sequences(x_train)\n",
        "    x_test_token = tokenizer.texts_to_sequences(x_test)\n",
        "    x_unlabel_token = tokenizer.texts_to_sequences(x_unlabel)\n",
        "    x_train_seq = sequence.pad_sequences(x_train_token, maxlen=maxlen,padding='post')\n",
        "    x_test_seq = sequence.pad_sequences(x_test_token, maxlen=maxlen,padding='post')\n",
        "    x_unlabel_tar= sequence.pad_sequences(x_unlabel_token, maxlen=maxlen,padding='post')\n",
        "    # defining vocalbury size\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "    x_train = x_train_seq\n",
        "    x_test = x_test_seq\n",
        "    return x_train, x_test , x_unlabel_tar, vocab_size, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AozvbK25RZ6m",
        "colab_type": "text"
      },
      "source": [
        "# Noise Creator "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-fC3dxbzJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def instant_noise(x_train, y_train, x_unlabel, n_ratio ):\n",
        "    '''this function introduce noise in the training data for mean teacher model , \n",
        "    this function is used in calculating classification cost, user have to provide \n",
        "    amount of noise, want to add(ratio) in train data and test train split ratio too'''\n",
        "    #amount of noise need to add in x_train data \n",
        "    noise=int(np.shape(x_train)[0]*n_ratio)\n",
        " \n",
        "    # taking column of x_train, need it later \n",
        "    x_column = np.shape(x_train)[1]\n",
        "\n",
        "    if noise <= int(np.shape(x_unlabel)[0]):\n",
        "\n",
        "        #taking number of noise from unlabel data \n",
        "        ratio_noise = x_unlabel[:noise]\n",
        "\n",
        "        # creating -1 label for noise data \n",
        "        y_unlabel=np.full((np.shape(ratio_noise)[0], 1), -1)\n",
        "\n",
        "        # adding noise in train data \n",
        "        x = np.append(x_train, ratio_noise, axis=0)\n",
        "        # print(np.shape(x))\n",
        "        y = np.append(y_train, y_unlabel, axis=0)\n",
        "        x = np.append(x,y, axis=1)\n",
        "        row = np.shape(x)[0]\n",
        "\n",
        "        # shufflin data \n",
        "        x =np.random.permutation(x)\n",
        "        # print(np.shape(x))\n",
        "\n",
        "        #seperating label from x \n",
        "        y_train_n=np.reshape(x[:,x_column],(row,1))\n",
        "        x_train_n=x[0:len(x),0:x_column]\n",
        "        # y_train_n= np.reshape(y[:len(x),0],(train_split,1))\n",
        "\n",
        "        \n",
        "    else :\n",
        "        print('error: Insufficient unlabel data available !')\n",
        "\n",
        "    return x_train_n, y_train_n\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4GUv0L7Wfrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from nltk import WordPunctTokenizer\n",
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "def embedding_creation(full_article):\n",
        "    word_punctuation_tokenizer = nltk.WordPunctTokenizer()\n",
        "    word_tokenized_corpus = [word_punctuation_tokenizer.tokenize(sent) for sent in full_article]\n",
        "    embedding_size = 60\n",
        "    window_size = 40\n",
        "    min_word = 5\n",
        "    down_sampling = 1e-2\n",
        "    embedd_model = FastText(word_tokenized_corpus,\n",
        "                      size=embedding_size,\n",
        "                      window=window_size,\n",
        "                      min_count=min_word,\n",
        "                      sample=down_sampling,\n",
        "                      sg=0,\n",
        "                      iter=50)\n",
        "    print('Finished and saving model at location', path)\n",
        "    embedd_model.save(path+'embedding_Model.model')\n",
        "    return \n",
        "\n",
        "\n",
        "def synonym_noise(x_batch,maxlen,tokenizer):\n",
        "    articles = tokenizer.sequences_to_texts(x_batch)\n",
        "    changed_articles=[]\n",
        "    model_embedd= FastText.load( path+'/embedding.model')\n",
        "    for article in articles:\n",
        "        word_array= article.split(' ')\n",
        "        sent1=[]\n",
        "        '''toss and taking random decision on data'''\n",
        "        if np.random.binomial(1, 0.5):\n",
        "            for word in word_array:\n",
        "                if word in model_embedd.wv.vocab:\n",
        "                    most_similar=model_embedd.wv.most_similar(word)\n",
        "                    # print(most_similar[0][0])\n",
        "                    #flipping coin to decide to change or not if head change word and if tails dont change\n",
        "                    #change p value for reducing or increasing the edit \n",
        "                    if np.random.binomial(1, 0.3):\n",
        "                        sent1.append(most_similar[0][0])\n",
        "                    else:\n",
        "                        sent1.append(word)\n",
        "                else:\n",
        "                    sent1.append(word)\n",
        "            joined_text = ' '.join(sent1)\n",
        "        else:\n",
        "            joined_text=' '.join(word_array)\n",
        "        changed_articles.append(joined_text)\n",
        "    x_train_seq_n = tokenizer.texts_to_sequences(changed_articles)\n",
        "    x_train_seq_n = sequence.pad_sequences(x_train_seq_n,maxlen=maxlen)\n",
        "    # x_train_seq_n=tf.convert_to_tensor(x_train_seq_n)\n",
        "    return x_train_seq_n\n",
        "def drop_out(x_batch,probability):\n",
        "    # print(type(x_batch))\n",
        "    for i in range(len(x_batch)):\n",
        "        for j in range(len(x_batch[i])):\n",
        "            if np.random.binomial(1, probability):\n",
        "                x_batch[i][j]=0\n",
        "            else:\n",
        "                continue\n",
        "    x_batch_1=tf.convert_to_tensor(x_batch)\n",
        "    return x_batch_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swtc3CtsvXH5",
        "colab_type": "text"
      },
      "source": [
        "# Model Declaration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aFjsH6yzgB4V",
        "colab": {}
      },
      "source": [
        "def BiLstmModel(maxlen, vocab_size):\n",
        "  tf.keras.backend.clear_session()\n",
        "  inputs = keras.Input(shape=(maxlen,))\n",
        "  x =Embedding(vocab_size, 128, input_length=None)(inputs)\n",
        "  x =Bidirectional(LSTM(128))(x)\n",
        "#   x = Dropout(0.2)(x)\n",
        "#   x =Dense(64,activation='relu')(x)\n",
        "  x =Dense(2)(x)\n",
        "  x =Dense(1, activation='sigmoid')(x)\n",
        "  return Model(inputs,x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrpTHBDBb4Uv",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR5z1R9C2big",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Function to create confusion matrix \n",
        "def Confusion_matrix(model,x_test,y_true, threshold, caption='Confusion matrix'):\n",
        "    '''this function will create confusion matrix with predicted value and true label'''\n",
        "    y_hat= model.predict(x_test)\n",
        "    y_pred=(np.greater_equal(y_hat,threshold)).astype(int)\n",
        "    cm=confusion_matrix(y_true,y_pred)\n",
        "    # print(cm)\n",
        "    # calculating recall , precision and f1 score \n",
        "    tp_and_fp=np.sum(cm[:,1])\n",
        "    tn_and_fp=np.sum(cm[0,:])\n",
        "    tp_and_fn = np.sum(cm[1, : ])\n",
        "    tp_and_tn= np.trace(cm)\n",
        "    tp=(tp_and_fp-tn_and_fp+tp_and_tn)/2\n",
        "    '''handling with divide by zero is pending'''\n",
        "    #TODO: handling of divide by zero \n",
        "    precision=tp/tp_and_fp \n",
        "    recall = tp/tp_and_fn\n",
        "    accuracy= np.trace(cm)/np.sum(cm)\n",
        "    # f1_score=sklearn.metrics.f1_score(y_true, y_pred)\n",
        "    f1_score= (2*precision*recall)/(precision+recall)\n",
        "    print('Precision:', precision)\n",
        "    print('Recall:', recall)\n",
        "    print('f1 Score:', f1_score)\n",
        "    print('Accuracy:', accuracy)\n",
        "\n",
        "    # import matplotlib.pyplot as plt\n",
        "    # figure = plt.figure(figsize=(8, 8))\n",
        "    # # cm=np.around(cm.astype(int))\n",
        "    # # con_mat_norm = np.around(cm, decimals=4)\n",
        "    # con_mat_norm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "    # sns.heatmap(con_mat_norm, annot=True,cmap=plt.cm.Oranges)\n",
        "    # plt.tight_layout()\n",
        "    # plt.ylabel('True label')\n",
        "    # plt.xlabel('Predicted label')\n",
        "    # plt.title(caption)\n",
        "    \n",
        "    # plt.show()\n",
        "    return cm, accuracy, precision, recall, f1_score\n",
        "def prec_rec_f1score(y_true,x_test,model):\n",
        "    from sklearn.metrics import precision_recall_fscore_support\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.metrics import precision_score\n",
        "    from sklearn.metrics import recall_score\n",
        "    from sklearn.metrics import f1_score\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()\n",
        "    y_hat= model.predict(x_test)\n",
        "    y_pred=(np.greater_equal(y_hat,0.51)).astype(int)\n",
        "    pr_re_f1score_perclass= precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    pr_re_f1score_average=precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
        "    precision=precision_score(y_true,y_pred,average=None)\n",
        "    recall = recall_score(y_true,y_pred,average=None)\n",
        "    accuracy= accuracy_score(y_true,y_pred)\n",
        "    f1_score=f1_score(y_true,y_pred)\n",
        "    #per class\n",
        "    precision_true=pr_re_f1score_perclass[0][1]\n",
        "    precision_fake=pr_re_f1score_perclass[0][0]\n",
        "    recall_true=pr_re_f1score_perclass[1][1]\n",
        "    recall_fake=pr_re_f1score_perclass[1][0]\n",
        "    f1score_true= pr_re_f1score_perclass[2][1]\n",
        "    f1score_fake= pr_re_f1score_perclass[2][0]\n",
        "    metrices_name=['accuracy','precision_true','precision_fake','recall_true','recall_fake','f1score_true','f1score_fake']\n",
        "    metrices_value=[accuracy, precision_true, precision_fake, recall_true, recall_fake, f1score_true, f1score_fake]\n",
        "    i=0\n",
        "    for item in metrices_name:\n",
        "        print(item +':' ,metrices_value[i])\n",
        "        i+=1\n",
        "    binary_loss= bce(y_true, y_hat).numpy()\n",
        "    print('Binary_loss',binary_loss)\n",
        "\n",
        "    return accuracy, precision_true, precision_fake, recall_true, recall_fake, f1score_true, f1score_fake,binary_loss \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aqHBEyRcJR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def scatter_plot(logits, y_t, title):\n",
        "    marker_size=20\n",
        "    figure = plt.figure(figsize=(20, 6))\n",
        "    plt.scatter(logits,logits, marker_size, c=y_t)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted Probability\")\n",
        "    plt.ylabel(\"Predicted Probability\")\n",
        "    cbar= plt.colorbar()\n",
        "    cbar.set_label(\"Probability\", labelpad=+1)\n",
        "    plt.show()\n",
        "    return\n",
        "\n",
        "# accuracy \n",
        "def model_evaluation(model, x_test, y_true, name):\n",
        "    y_hat= model(x_test)\n",
        "    y_pred=(np.greater(y_hat,0.505)).astype(int)\n",
        "    cm=confusion_matrix(y_true,y_pred)\n",
        "    \n",
        "    accuracy= np.trace(cm)/np.sum(cm)\n",
        "    \n",
        "    print(name+ \":\")\n",
        "  \n",
        "    print(' Accuracy:', accuracy)\n",
        "\n",
        "    # this will plot the result \n",
        "    # scatter_plot(y_hat,y_true, title=name)\n",
        "\n",
        "    return accuracy #precision, recall, f1_score, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYaio-ylcL3b",
        "colab_type": "text"
      },
      "source": [
        "# Cost Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3YuD3mOcO4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# declaring loss function\n",
        "# ref:https://github.com/CuriousAI/mean-teacher/tree/master/tensorflow/mean_teacher  updated according to our need .\n",
        "def classification_costs(logits, labels):\n",
        "    \"\"\" Commputing classification cost , after removing labels -1 of unlabelled data and then calculating \n",
        "    the binary cross entropy .\n",
        "    \"\"\"\n",
        "    applicable = tf.not_equal(labels, -1)\n",
        "\n",
        "     # Change -1s to zeros to make cross-entropy computable\n",
        "    labels = tf.where(applicable, labels, tf.zeros_like(labels))\n",
        "\n",
        "    # This will now have incorrect values for unlabeled examples\n",
        "    per_sample = tf.keras.losses.binary_crossentropy(labels,logits)\n",
        "    # Retain costs only for labeled\n",
        "    per_sample = tf.where(applicable, per_sample, tf.zeros_like(per_sample))\n",
        "    # Take mean over all examples, not just labeled examples.\n",
        "    # print('sample', np.shape(per_sample))\n",
        "    loss = tf.math.divide( tf.reduce_mean(tf.reduce_sum(per_sample)), np.shape(per_sample)[0])\n",
        "\n",
        "    return loss\n",
        "\n",
        "#custom loss function\n",
        "def Overall_Cost(classification_cost, consistency_cost, ratio=0.5):\n",
        "    return (ratio * classification_cost) + ((1 - ratio)*consistency_cost)\n",
        "#function for consistency cost \n",
        "def Consistency_Cost(teacher_output, student_output):\n",
        "    #Kl divergence \n",
        "    # kl = tf.keras.losses.KLDivergence()\n",
        "    # sq_diff_layer=kl(teacher_output, student_output).numpy()\n",
        "    \n",
        "    #MSE\n",
        "    sq_diff_layer = tf.reduce_mean(tf.math.squared_difference(teacher_output, student_output))\n",
        "    return sq_diff_layer\n",
        "def ema(student_model, teacher_model, alpha):\n",
        "    '''\n",
        "    Calculates the exponential moving average of the student model weights and updates the teacher model weights\n",
        "    formula:\n",
        "    t_i = alpha * t_{i-1} + (1 - alpha) * s_i, with default alpha = 0.99\n",
        "    t_i = weights of teacher model in current epoch\n",
        "    s_i = weights of student model in current epoch\n",
        "    '''\n",
        "    #taking weights \n",
        "    student_weights = student_model.get_weights()\n",
        "    teacher_weights = teacher_model.get_weights()\n",
        "\n",
        "    #length must be equal otherwise it will not work \n",
        "    assert len(student_weights) == len(teacher_weights), 'length of student and teachers weights are not equal Please check. \\n Student: {}, \\n Teacher:{}'.format(\n",
        "        len(student_weights), len(teacher_weights))\n",
        "\n",
        "    new_layers = []\n",
        "    for i, layers in enumerate(student_weights):\n",
        "        new_layer = alpha*(teacher_weights[i]) + (1-alpha)*layers\n",
        "        new_layers.append(new_layer)\n",
        "    teacher_model.set_weights(new_layers)\n",
        "    return teacher_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJqtMkOXbi3s",
        "colab_type": "text"
      },
      "source": [
        "# Writing Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIF13BPMbm3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def report_writing(Model,lr,Batch_Size, Epoch,Alpha,Ratio, train_accuracy,test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake,Classification_Loss,comment):\n",
        "    x = datetime.datetime.now()\n",
        "    report_df = pd.DataFrame(columns=['Date', 'Model','Learning Rate','Batch_Size', 'Epoch','Alpha','Ratio','Train_Accuracy',\n",
        "                                      'Test_Accuracy', 'Precision_True','Precision_Fake','Recall_True','Recall_Fake','F1_Score_True','F1_Score_Fake','Classification_Loss',\n",
        "                                      'comment'])\n",
        "    report_df = report_df.append({'Date' : x.strftime(\"%c\"), 'Model' :Model,'Learning Rate':lr,'Batch_Size' : Batch_Size, 'Epoch': Epoch,'Alpha': Alpha,'Ratio': Ratio,'Train_Accuracy': train_accuracy,\n",
        "                                  'Test_Accuracy': test_accuracy, 'Precision_True': precision_true,'Precision_Fake': precision_fake,'Recall_True': recall_true,'Recall_Fake': recall_fake,'F1_Score_True': f1score_true,'F1_Score_Fake': f1score_fake, 'Classification_Loss':Classification_Loss,'comment': comment}, ignore_index=True)\n",
        "    my_file = Path(path+'/report_synonym_dropout_0.99_maxlen.csv')\n",
        "\n",
        "    if my_file.exists():\n",
        "        report_df.to_csv(path+'/report_synonym_dropout_0.99_maxlen.csv',mode='a', header= False , index = False)\n",
        "    else:\n",
        "        report_df.to_csv(path+'/report_synonym_dropout_0.99_maxlen.csv',mode='w', header= True , index= False) \n",
        "    return \n",
        "\n",
        "# report_writing('Supervised-BiLstm', 124,10,34, 0.5, 0.99,0.90,0.90,0.90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od1jiX4KlyM8",
        "colab_type": "text"
      },
      "source": [
        "# Loading data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3LTSmmyl0ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def loading_data():\n",
        "    if not os.path.isfile(path+'/xte_shuffled.npy'):\n",
        "        print(\"Please clean the data first or the location of npy file is incorrect, Checking function Loading_data\")\n",
        "    else:\n",
        "      x_tr = np.load(path+'/xtr_shuffled.npy',allow_pickle=True)\n",
        "      x_te = np.load(path+'/xte_shuffled.npy',allow_pickle=True)\n",
        "      y_tr = np.load(path+'/ytr_shuffled.npy',allow_pickle=True)\n",
        "      y_te = np.load(path+'/yte_shuffled.npy',allow_pickle=True)\n",
        "      x_un = np.load(path+'/xun_shuffled.npy',allow_pickle=True)\n",
        "    #   print(\"train Data_Size:\",  np.shape(x_tr))\n",
        "    #   print(\"test Data_Size:\",  np.shape(x_te))\n",
        "      \n",
        "\n",
        "\n",
        "      # Performing Kfold here \n",
        "    return x_tr, y_tr, x_te, y_te, x_un\n",
        "\n",
        "\n",
        "def Kfold_crossvalidation(x_train,y_train,x_test,y_test):\n",
        "    '''this function is for k_fold crossvalidation implementation'''\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    data= np.append(x_train, x_test, axis=0)\n",
        "    label= np.append(y_train,y_test, axis=0)\n",
        "    column_size= np.shape(data)[1]\n",
        "    # combining whole data\n",
        "    whole_data=np.append(data,label.astype(int),axis=1)\n",
        "    whole_data= np.random.permutation(whole_data)\n",
        "    whole_label= whole_data[:][:,-1:]\n",
        "    whole_data= whole_data[:][:,:column_size]\n",
        "    x_tr, x_te, y_tr, y_te = train_test_split(whole_data, whole_label, test_size=0.33)\n",
        "    return x_tr, y_tr, x_te, y_te"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt6qGg9JOUFI",
        "colab_type": "text"
      },
      "source": [
        "# Supervised Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGh0wEpCz7wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def train_supervised(epochs, batch_size, lr, x_train, y_train, x_test, y_test,maxlen,vocab_size):\n",
        "\n",
        "    model_supervised = BiLstmModel(maxlen, vocab_size)\n",
        "    model_supervised.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= lr ),loss= 'binary_crossentropy', metrics=['accuracy'])\n",
        "    print('Training supervised Model...')\n",
        "    history=model_supervised.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,validation_split=0.25)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()  \n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # evaluation\n",
        "    train_accuracy=history.history['accuracy'][len(history.epoch)-1]\n",
        "       \n",
        "    test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake,binary_loss = prec_rec_f1score(y_test,x_test,model_supervised)\n",
        "    cm, test_accuracy, precision, recall, f1_score =Confusion_matrix(model_supervised,x_test,y_test,0.51, 'Supervised model')\n",
        "    report_writing('Supervised_BILSTM',lr, batch_size,len(history.epoch),'NaN','NaN', train_accuracy, \n",
        "                   test_accuracy, precision_true, precision_fake, recall_true, recall_fake, \n",
        "                   f1score_true, f1score_fake,binary_loss,'Baseline')    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA3VRaeujjfn",
        "colab_type": "text"
      },
      "source": [
        "# MEAN teacher\n",
        "In this updation takes place during each step/batch. This model doesnt work "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf7EK71Fl-zo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_MeanTeacher(epochs, batch_size, alpha, lr, ratio,x_train, y_train, x_test, y_test, x_unlabel_tar,vocab_size, tokenizer,maxlen):\n",
        "    #splitting training data \n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25)\n",
        "\n",
        "\n",
        "    #preparing the training dataset\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    # Prepare the validation dataset.\n",
        "    # val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    # val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "    #preparing the target dataset \n",
        "    tar_dataset =  tf.data.Dataset.from_tensor_slices(x_unlabel_tar)\n",
        "    tar_dataset = tar_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    #declaring optimiser\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate= lr ) #trying changing learning rate , sometimes it gives good result \n",
        "    train_metrics = tf.keras.metrics.BinaryAccuracy(name='Binary_Accuracy')\n",
        "    val_acc_metric = tf.keras.metrics.BinaryAccuracy(name=\"Binary_Acc\")\n",
        "    teacher_acc_metric = tf.keras.metrics.BinaryAccuracy(name=\"Binary_Acc_teacher\") \n",
        "    # Creating model\n",
        "    student = BiLstmModel(maxlen, vocab_size)\n",
        "    teacher = BiLstmModel(maxlen, vocab_size)\n",
        "\n",
        "\n",
        "    # collecting costs\n",
        "    #this one for collecting the costs\n",
        "    # consistency=[]\n",
        "    # overall=[]\n",
        "    # classification=[]\n",
        "    train_accuracy=[]\n",
        "    steps=[]\n",
        "\n",
        "    # iterator_unlabel = iter(tar_dataset)\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "    #training teacher with one epoch \n",
        "   \n",
        "    #this I am doing to get all steps details in epoch\n",
        "    i=0\n",
        "    print('Train Mean teacher Model...')\n",
        "    teacher.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
        "    teacher.fit(x_train,y_train, batch_size=batch_size, epochs=1)\n",
        "\n",
        "    acc_t=0\n",
        "    x_unlabel_tar= tf.convert_to_tensor(x_unlabel_tar)\n",
        "    for epoch in range(1,epochs+1):  \n",
        "        print(*\"*****************\")\n",
        "        print('Start of epoch %d' % (epoch,))\n",
        "        print(*\"*****************\")\n",
        "        #iteration over batches \n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "             with tf.GradientTape() as tape:\n",
        "         \n",
        "                # adding instant noise\n",
        "                iterator_unlabel = iter(tar_dataset)\n",
        "                x_batch_unlabel = iterator_unlabel.get_next()\n",
        "\n",
        "\n",
        "                \n",
        "                '''this is related to change with synonyms in articles'''\n",
        "                # x_batch_sn= synonym_noise(x_batch_train.numpy(),maxlen,tokenizer)\n",
        "                x_batch_dp= drop_out(x_batch_train.numpy(),0.2)\n",
        "\n",
        "                '''this is one method of adding -1 label using unlable data'''\n",
        "                # x_train_n,y_train_n= instant_noise(x_batch_train,y_batch_train,x_batch_unlabel,0.2)\n",
        "\n",
        "                # Run the forward pass of the layer\n",
        "                logits= student(x_batch_dp, training= True)  \n",
        "                # logits_acc =  student(x_batch_sn, training= False) \n",
        "\n",
        "                # TODO:this  metrics also have to right \n",
        "                train_metrics(y_batch_train,logits)  \n",
        "\n",
        "                #Calculating classification cost \n",
        "                classification_cost = classification_costs(logits,y_batch_train)\n",
        "\n",
        "                x_batch_dp1= drop_out(x_batch_train.numpy(),0.2)\n",
        "                \n",
        "                # tar_student= student(x_batch_dp1)\n",
        "                tar_teacher = teacher(x_batch_dp1) #x_batch_train\n",
        "                #  tar_student= student(x_train_n)\n",
        "                consistency_cost= Consistency_Cost(tar_teacher,logits) \n",
        "                # consistency.append(consistency_cost)\n",
        "\n",
        "                overall_cost= Overall_Cost(classification_cost, consistency_cost, ratio=0.5)\n",
        "                # overall.append(overall_cost)\n",
        "                #  consistency_cost = consistency_cost #this is ratio \n",
        "                #adding loss to student model \n",
        "             grads= tape.gradient(overall_cost, student.trainable_weights)\n",
        "             i=i+1\n",
        "             steps.append(i)\n",
        "   \n",
        "             # the value of the variables to minimize the loss.\n",
        "             optimizer.apply_gradients(zip(grads, student.trainable_weights))\n",
        "             teacher= ema(student, teacher, alpha=alpha)\n",
        "\n",
        "        train_acc = train_metrics.result()\n",
        "        print(alpha)\n",
        "   \n",
        "        #appending training accuracy\n",
        "        train_accuracy.append(train_acc)\n",
        "\n",
        "        # print('Training acc over epoch: %s' % (float(train_acc)*100,))\n",
        "        # Reset training metrics at the end of each epoch\n",
        "        train_metrics.reset_states()\n",
        "   \n",
        "        # Run a validation loop at the end of each epoch.\n",
        "        print('*******STUDENT*************')\n",
        "        prec_rec_f1score(y_val,x_val,student)\n",
        "        print('*******TEACHER*************')\n",
        "        prec_rec_f1score(y_val,x_val,teacher)\n",
        "\n",
        "\n",
        "        if epoch >= 10 and epoch % 5 ==0 :\n",
        "            print('---------------------------STUDENT--------------------------')\n",
        "            test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake,binary_loss = prec_rec_f1score(y_test,x_test,student)\n",
        "            report_writing('Student',lr, batch_size,epoch,alpha,ratio, train_acc.numpy(), \n",
        "                           test_accuracy, precision_true, precision_fake, recall_true, recall_fake, \n",
        "                           f1score_true, f1score_fake,binary_loss,'Noise-using-synonym')  \n",
        "            print('-----------------------------------------------------------------')\n",
        "    \n",
        "            print('---------------------------TEACHER---------------------------------')\n",
        "        #    cm, test_accuracy, precision, recall, f1_score =Confusion_matrix(teacher,x_test,y_test,0.51, 'Teacher model')\n",
        "            test_accuracy,precision_true,precision_fake,recall_true,recall_fake,f1score_true,f1score_fake,binary_loss = prec_rec_f1score(y_test,x_test,teacher)\n",
        "            report_writing('Teacher',lr, batch_size,epoch,alpha,ratio, train_acc.numpy(), \n",
        "                           test_accuracy, precision_true, precision_fake, recall_true, recall_fake, \n",
        "                           f1score_true, f1score_fake,binary_loss,'Noise-using-synonym') \n",
        "            print('-----------------------------------------------------------------')\n",
        "    tf.keras.backend.clear_session()\n",
        "    return\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl5N2ius2gnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05f7bcfa-ae8e-4a9c-8cea-7512aabdf2ae"
      },
      "source": [
        "if __name__ == '__main__':\n",
        " \n",
        "\n",
        "    # k fold function calling \n",
        "    lr=0.0001\n",
        "    epochs=30\n",
        "    batch_size= 64\n",
        "    #for mean teacher \n",
        "    ratio =0.5\n",
        "    alpha=0.99 #(0.90-0.99)\n",
        "    maxlen=100\n",
        "    x_train, y_train, x_test, y_test, x_unlabel = loading_data()\n",
        "    x_train, x_test, x_unlabel, vocab_size, tokenizer = tokenization(x_train,x_test, x_unlabel, maxlen)\n",
        " \n",
        "    for i in range(0,100):\n",
        "\n",
        "        x_train, y_train, x_test, y_test = Kfold_crossvalidation(x_train,y_train,x_test,y_test)\n",
        "\n",
        "        print(\"train Data_Size:\",  np.shape(x_train))\n",
        "        print(\"test Data_Size:\",  np.shape(x_test))\n",
        "        print('Train Label count: True, Fake', np.count_nonzero(y_train==1),np.count_nonzero(y_train==0))\n",
        "        print('Test Label count : True, Fake', np.count_nonzero(y_test==1),np.count_nonzero(y_test==0))\n",
        "        # train_supervised(epochs, batch_size, lr,x_train, y_train, x_test, y_test,maxlen,vocab_size)\n",
        "        train_MeanTeacher(epochs, batch_size, alpha, lr, ratio,x_train, y_train, x_test, y_test, x_unlabel,vocab_size, tokenizer,maxlen)\n",
        "        # resetting the environment\n",
        "        tf.keras.backend.clear_session()\n",
        "        # get_ipython().magic('reset -sf')\n",
        "    print('finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 820 810\n",
            "Test Label count : True, Fake 439 364\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 440ms/step - loss: 0.6936 - accuracy: 0.5008\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "recall_fake: 0.6820512820512821\n",
            "f1score_true: 0.661800486618005\n",
            "f1score_fake: 0.6567901234567901\n",
            "Binary_loss 1.4554344\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.6945812807881774\n",
            "precision_fake: 0.6487804878048781\n",
            "recall_true: 0.6619718309859155\n",
            "recall_fake: 0.6820512820512821\n",
            "f1score_true: 0.6778846153846153\n",
            "f1score_fake: 0.6650000000000001\n",
            "Binary_loss 1.0954465\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 30\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.6611570247933884\n",
            "precision_fake: 0.6807228915662651\n",
            "recall_true: 0.7511737089201878\n",
            "recall_fake: 0.5794871794871795\n",
            "f1score_true: 0.7032967032967034\n",
            "f1score_fake: 0.6260387811634349\n",
            "Binary_loss 1.580175\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.693069306930693\n",
            "precision_fake: 0.6456310679611651\n",
            "recall_true: 0.6572769953051644\n",
            "recall_fake: 0.6820512820512821\n",
            "f1score_true: 0.674698795180723\n",
            "f1score_fake: 0.6633416458852868\n",
            "Binary_loss 1.1582022\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6438356164383562\n",
            "precision_true: 0.628968253968254\n",
            "precision_fake: 0.6688963210702341\n",
            "recall_true: 0.7620192307692307\n",
            "recall_fake: 0.5167958656330749\n",
            "f1score_true: 0.6891304347826086\n",
            "f1score_fake: 0.5830903790087464\n",
            "Binary_loss 1.5457321\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6550435865504358\n",
            "precision_true: 0.665871121718377\n",
            "precision_fake: 0.6432291666666666\n",
            "recall_true: 0.6706730769230769\n",
            "recall_fake: 0.6382428940568475\n",
            "f1score_true: 0.6682634730538922\n",
            "f1score_fake: 0.6407263294422828\n",
            "Binary_loss 1.0925308\n",
            "-----------------------------------------------------------------\n",
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 833 797\n",
            "Test Label count : True, Fake 426 377\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 429ms/step - loss: 0.6928 - accuracy: 0.5205\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5024509803921569\n",
            "precision_true: 0.5042372881355932\n",
            "precision_fake: 0.5\n",
            "recall_true: 0.5804878048780487\n",
            "recall_fake: 0.4236453201970443\n",
            "f1score_true: 0.5396825396825398\n",
            "f1score_fake: 0.45866666666666667\n",
            "Binary_loss 0.6929768\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49754901960784315\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6644844517184942\n",
            "Binary_loss 0.6929968\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 2\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.4877450980392157\n",
            "precision_true: 0.49280575539568344\n",
            "precision_fake: 0.47692307692307695\n",
            "recall_true: 0.6682926829268293\n",
            "recall_fake: 0.3054187192118227\n",
            "f1score_true: 0.567287784679089\n",
            "f1score_fake: 0.37237237237237236\n",
            "Binary_loss 0.69283086\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49754901960784315\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6644844517184942\n",
            "Binary_loss 0.6930116\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 3\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.4946236559139785\n",
            "precision_fake: 0.4806201550387597\n",
            "recall_true: 0.6731707317073171\n",
            "recall_fake: 0.3054187192118227\n",
            "f1score_true: 0.5702479338842975\n",
            "f1score_fake: 0.37349397590361444\n",
            "Binary_loss 0.6928127\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49754901960784315\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6644844517184942\n",
            "Binary_loss 0.6929923\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 4\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.4946236559139785\n",
            "precision_fake: 0.4806201550387597\n",
            "recall_true: 0.6731707317073171\n",
            "recall_fake: 0.3054187192118227\n",
            "f1score_true: 0.5702479338842975\n",
            "f1score_fake: 0.37349397590361444\n",
            "Binary_loss 0.6914084\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49754901960784315\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6644844517184942\n",
            "Binary_loss 0.6929046\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 5\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5098039215686274\n",
            "precision_true: 0.5088967971530249\n",
            "precision_fake: 0.5118110236220472\n",
            "recall_true: 0.697560975609756\n",
            "recall_fake: 0.32019704433497537\n",
            "f1score_true: 0.588477366255144\n",
            "f1score_fake: 0.3939393939393939\n",
            "Binary_loss 0.6890181\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49754901960784315\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6644844517184942\n",
            "Binary_loss 0.69271946\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 6\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5661764705882353\n",
            "precision_true: 0.6794871794871795\n",
            "precision_fake: 0.5393939393939394\n",
            "recall_true: 0.25853658536585367\n",
            "recall_fake: 0.8768472906403941\n",
            "f1score_true: 0.3745583038869258\n",
            "f1score_fake: 0.6679174484052532\n",
            "Binary_loss 0.67789024\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.4987714987714988\n",
            "recall_true: 0.004878048780487805\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.009708737864077669\n",
            "f1score_fake: 0.6655737704918032\n",
            "Binary_loss 0.6923726\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 7\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5857843137254902\n",
            "precision_true: 0.55625\n",
            "precision_fake: 0.6931818181818182\n",
            "recall_true: 0.8682926829268293\n",
            "recall_fake: 0.30049261083743845\n",
            "f1score_true: 0.6780952380952382\n",
            "f1score_fake: 0.41924398625429554\n",
            "Binary_loss 0.6733508\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5392156862745098\n",
            "precision_true: 0.6440677966101694\n",
            "precision_fake: 0.5214899713467048\n",
            "recall_true: 0.18536585365853658\n",
            "recall_fake: 0.896551724137931\n",
            "f1score_true: 0.28787878787878785\n",
            "f1score_fake: 0.6594202898550725\n",
            "Binary_loss 0.69173795\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 8\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6176470588235294\n",
            "precision_true: 0.6296296296296297\n",
            "precision_fake: 0.6073059360730594\n",
            "recall_true: 0.5804878048780487\n",
            "recall_fake: 0.6551724137931034\n",
            "f1score_true: 0.6040609137055837\n",
            "f1score_fake: 0.6303317535545023\n",
            "Binary_loss 0.6433181\n",
            "*******TEACHER*************\n",
            "accuracy: 0.553921568627451\n",
            "precision_true: 0.5771812080536913\n",
            "precision_fake: 0.5405405405405406\n",
            "recall_true: 0.4195121951219512\n",
            "recall_fake: 0.6896551724137931\n",
            "f1score_true: 0.4858757062146893\n",
            "f1score_fake: 0.6060606060606061\n",
            "Binary_loss 0.690734\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 9\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6029411764705882\n",
            "precision_true: 0.9215686274509803\n",
            "precision_fake: 0.5574229691876751\n",
            "recall_true: 0.22926829268292684\n",
            "recall_fake: 0.9802955665024631\n",
            "f1score_true: 0.36718749999999994\n",
            "f1score_fake: 0.7107142857142856\n",
            "Binary_loss 0.6518361\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5686274509803921\n",
            "precision_true: 0.5911949685534591\n",
            "precision_fake: 0.5542168674698795\n",
            "recall_true: 0.4585365853658537\n",
            "recall_fake: 0.6798029556650246\n",
            "f1score_true: 0.5164835164835165\n",
            "f1score_fake: 0.6106194690265486\n",
            "Binary_loss 0.6891201\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 10\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6151960784313726\n",
            "precision_true: 0.5718562874251497\n",
            "precision_fake: 0.8108108108108109\n",
            "recall_true: 0.9317073170731708\n",
            "recall_fake: 0.2955665024630542\n",
            "f1score_true: 0.7087198515769945\n",
            "f1score_fake: 0.4332129963898918\n",
            "Binary_loss 0.6563386\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5735294117647058\n",
            "precision_true: 0.6054421768707483\n",
            "precision_fake: 0.5555555555555556\n",
            "recall_true: 0.43414634146341463\n",
            "recall_fake: 0.7142857142857143\n",
            "f1score_true: 0.5056818181818182\n",
            "f1score_fake: 0.6250000000000001\n",
            "Binary_loss 0.68677074\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6488169364881694\n",
            "precision_true: 0.6111111111111112\n",
            "precision_fake: 0.8064516129032258\n",
            "recall_true: 0.9295774647887324\n",
            "recall_fake: 0.33156498673740054\n",
            "f1score_true: 0.7374301675977653\n",
            "f1score_fake: 0.46992481203007513\n",
            "Binary_loss 0.6304174\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6164383561643836\n",
            "precision_true: 0.6993243243243243\n",
            "precision_fake: 0.5680473372781065\n",
            "recall_true: 0.4859154929577465\n",
            "recall_fake: 0.7639257294429708\n",
            "f1score_true: 0.5734072022160664\n",
            "f1score_fake: 0.65158371040724\n",
            "Binary_loss 0.68412244\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 11\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.5933609958506224\n",
            "precision_fake: 0.6287425149700598\n",
            "recall_true: 0.697560975609756\n",
            "recall_fake: 0.5172413793103449\n",
            "f1score_true: 0.6412556053811659\n",
            "f1score_fake: 0.5675675675675675\n",
            "Binary_loss 0.70807534\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6004901960784313\n",
            "precision_true: 0.64\n",
            "precision_fake: 0.5775193798449613\n",
            "recall_true: 0.4682926829268293\n",
            "recall_fake: 0.7339901477832512\n",
            "f1score_true: 0.5408450704225353\n",
            "f1score_fake: 0.6464208242950109\n",
            "Binary_loss 0.68358517\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 12\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6274509803921569\n",
            "precision_true: 0.6167400881057269\n",
            "precision_fake: 0.6408839779005525\n",
            "recall_true: 0.6829268292682927\n",
            "recall_fake: 0.5714285714285714\n",
            "f1score_true: 0.6481481481481481\n",
            "f1score_fake: 0.6041666666666667\n",
            "Binary_loss 0.7423842\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.68\n",
            "precision_fake: 0.5759717314487632\n",
            "recall_true: 0.4146341463414634\n",
            "recall_fake: 0.8029556650246306\n",
            "f1score_true: 0.5151515151515151\n",
            "f1score_fake: 0.6707818930041153\n",
            "Binary_loss 0.6790755\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 13\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6666666666666666\n",
            "precision_true: 0.7555555555555555\n",
            "precision_fake: 0.6227106227106227\n",
            "recall_true: 0.4975609756097561\n",
            "recall_fake: 0.8374384236453202\n",
            "f1score_true: 0.6\n",
            "f1score_fake: 0.7142857142857143\n",
            "Binary_loss 0.69623584\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6299019607843137\n",
            "precision_true: 0.7109375\n",
            "precision_fake: 0.5928571428571429\n",
            "recall_true: 0.44390243902439025\n",
            "recall_fake: 0.8177339901477833\n",
            "f1score_true: 0.5465465465465467\n",
            "f1score_fake: 0.6873706004140787\n",
            "Binary_loss 0.6724681\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 14\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6568627450980392\n",
            "precision_true: 0.7304964539007093\n",
            "precision_fake: 0.6179775280898876\n",
            "recall_true: 0.5024390243902439\n",
            "recall_fake: 0.812807881773399\n",
            "f1score_true: 0.5953757225433526\n",
            "f1score_fake: 0.7021276595744681\n",
            "Binary_loss 0.7236702\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6421568627450981\n",
            "precision_true: 0.7092198581560284\n",
            "precision_fake: 0.6067415730337079\n",
            "recall_true: 0.4878048780487805\n",
            "recall_fake: 0.7980295566502463\n",
            "f1score_true: 0.5780346820809248\n",
            "f1score_fake: 0.6893617021276596\n",
            "Binary_loss 0.6613271\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 15\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.69375\n",
            "precision_fake: 0.6209677419354839\n",
            "recall_true: 0.5414634146341464\n",
            "recall_fake: 0.7586206896551724\n",
            "f1score_true: 0.6082191780821917\n",
            "f1score_fake: 0.6829268292682927\n",
            "Binary_loss 0.6709469\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6470588235294118\n",
            "precision_true: 0.6685082872928176\n",
            "precision_fake: 0.6299559471365639\n",
            "recall_true: 0.5902439024390244\n",
            "recall_fake: 0.7044334975369458\n",
            "f1score_true: 0.626943005181347\n",
            "f1score_fake: 0.6651162790697674\n",
            "Binary_loss 0.6430212\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.660024906600249\n",
            "precision_true: 0.7558528428093646\n",
            "precision_fake: 0.6031746031746031\n",
            "recall_true: 0.5305164319248826\n",
            "recall_fake: 0.8063660477453581\n",
            "f1score_true: 0.623448275862069\n",
            "f1score_fake: 0.6901248581157775\n",
            "Binary_loss 0.6442906\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6787048567870486\n",
            "precision_true: 0.7427745664739884\n",
            "precision_fake: 0.6301969365426696\n",
            "recall_true: 0.6032863849765259\n",
            "recall_fake: 0.7639257294429708\n",
            "f1score_true: 0.6658031088082901\n",
            "f1score_fake: 0.6906474820143885\n",
            "Binary_loss 0.63523287\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 16\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.7821782178217822\n",
            "precision_fake: 0.5895765472312704\n",
            "recall_true: 0.3853658536585366\n",
            "recall_fake: 0.8916256157635468\n",
            "f1score_true: 0.5163398692810458\n",
            "f1score_fake: 0.7098039215686275\n",
            "Binary_loss 0.77164936\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.6371681415929203\n",
            "precision_fake: 0.6648351648351648\n",
            "recall_true: 0.7024390243902439\n",
            "recall_fake: 0.5960591133004927\n",
            "f1score_true: 0.6682134570765661\n",
            "f1score_fake: 0.6285714285714286\n",
            "Binary_loss 0.6187022\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 17\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.7155172413793104\n",
            "precision_fake: 0.5821917808219178\n",
            "recall_true: 0.40487804878048783\n",
            "recall_fake: 0.8374384236453202\n",
            "f1score_true: 0.5171339563862929\n",
            "f1score_fake: 0.6868686868686869\n",
            "Binary_loss 0.8601767\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.6245059288537549\n",
            "precision_fake: 0.6967741935483871\n",
            "recall_true: 0.7707317073170732\n",
            "recall_fake: 0.5320197044334976\n",
            "f1score_true: 0.6899563318777292\n",
            "f1score_fake: 0.6033519553072626\n",
            "Binary_loss 0.6030745\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 18\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.6890243902439024\n",
            "precision_fake: 0.6229508196721312\n",
            "recall_true: 0.551219512195122\n",
            "recall_fake: 0.7487684729064039\n",
            "f1score_true: 0.6124661246612466\n",
            "f1score_fake: 0.6800894854586129\n",
            "Binary_loss 0.6735729\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6421568627450981\n",
            "precision_true: 0.6096654275092936\n",
            "precision_fake: 0.7050359712230215\n",
            "recall_true: 0.8\n",
            "recall_fake: 0.4827586206896552\n",
            "f1score_true: 0.6919831223628692\n",
            "f1score_fake: 0.5730994152046784\n",
            "Binary_loss 0.6097064\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 19\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6151960784313726\n",
            "precision_true: 0.581081081081081\n",
            "precision_fake: 0.7053571428571429\n",
            "recall_true: 0.8390243902439024\n",
            "recall_fake: 0.3891625615763547\n",
            "f1score_true: 0.686626746506986\n",
            "f1score_fake: 0.5015873015873016\n",
            "Binary_loss 0.967034\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6299019607843137\n",
            "precision_true: 0.5924657534246576\n",
            "precision_fake: 0.7241379310344828\n",
            "recall_true: 0.8439024390243902\n",
            "recall_fake: 0.41379310344827586\n",
            "f1score_true: 0.6961770623742455\n",
            "f1score_fake: 0.5266457680250783\n",
            "Binary_loss 0.6252137\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 20\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6544117647058824\n",
            "precision_true: 0.6467889908256881\n",
            "precision_fake: 0.6631578947368421\n",
            "recall_true: 0.6878048780487804\n",
            "recall_fake: 0.6206896551724138\n",
            "f1score_true: 0.6666666666666666\n",
            "f1score_fake: 0.6412213740458015\n",
            "Binary_loss 0.8232964\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6348039215686274\n",
            "precision_true: 0.5972222222222222\n",
            "precision_fake: 0.725\n",
            "recall_true: 0.8390243902439024\n",
            "recall_fake: 0.42857142857142855\n",
            "f1score_true: 0.6977687626774848\n",
            "f1score_fake: 0.5386996904024768\n",
            "Binary_loss 0.6439676\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6899128268991283\n",
            "precision_true: 0.7102137767220903\n",
            "precision_fake: 0.6675392670157068\n",
            "recall_true: 0.7018779342723005\n",
            "recall_fake: 0.6763925729442971\n",
            "f1score_true: 0.706021251475797\n",
            "f1score_fake: 0.6719367588932806\n",
            "Binary_loss 0.6985146\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6899128268991283\n",
            "precision_true: 0.6577540106951871\n",
            "precision_fake: 0.7644628099173554\n",
            "recall_true: 0.8661971830985915\n",
            "recall_fake: 0.4907161803713528\n",
            "f1score_true: 0.7477203647416413\n",
            "f1score_fake: 0.5977382875605816\n",
            "Binary_loss 0.6073243\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 21\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6470588235294118\n",
            "precision_true: 0.6431924882629108\n",
            "precision_fake: 0.6512820512820513\n",
            "recall_true: 0.6682926829268293\n",
            "recall_fake: 0.625615763546798\n",
            "f1score_true: 0.6555023923444977\n",
            "f1score_fake: 0.6381909547738694\n",
            "Binary_loss 0.9046455\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6299019607843137\n",
            "precision_true: 0.59375\n",
            "precision_fake: 0.7166666666666667\n",
            "recall_true: 0.8341463414634146\n",
            "recall_fake: 0.4236453201970443\n",
            "f1score_true: 0.693711967545639\n",
            "f1score_fake: 0.5325077399380805\n",
            "Binary_loss 0.6753546\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 22\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6470588235294118\n",
            "precision_true: 0.7019867549668874\n",
            "precision_fake: 0.6147859922178989\n",
            "recall_true: 0.5170731707317073\n",
            "recall_fake: 0.7783251231527094\n",
            "f1score_true: 0.5955056179775281\n",
            "f1score_fake: 0.6869565217391305\n",
            "Binary_loss 0.8096642\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6274509803921569\n",
            "precision_true: 0.5923344947735192\n",
            "precision_fake: 0.7107438016528925\n",
            "recall_true: 0.8292682926829268\n",
            "recall_fake: 0.4236453201970443\n",
            "f1score_true: 0.6910569105691057\n",
            "f1score_fake: 0.5308641975308641\n",
            "Binary_loss 0.7186704\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 23\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6446078431372549\n",
            "precision_true: 0.6388888888888888\n",
            "precision_fake: 0.6510416666666666\n",
            "recall_true: 0.6731707317073171\n",
            "recall_fake: 0.6157635467980296\n",
            "f1score_true: 0.6555819477434679\n",
            "f1score_fake: 0.6329113924050632\n",
            "Binary_loss 0.7923853\n",
            "*******TEACHER*************\n",
            "accuracy: 0.625\n",
            "precision_true: 0.5942028985507246\n",
            "precision_fake: 0.6893939393939394\n",
            "recall_true: 0.8\n",
            "recall_fake: 0.4482758620689655\n",
            "f1score_true: 0.681912681912682\n",
            "f1score_fake: 0.5432835820895523\n",
            "Binary_loss 0.7141436\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 24\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.6244541484716157\n",
            "precision_fake: 0.6536312849162011\n",
            "recall_true: 0.697560975609756\n",
            "recall_fake: 0.5763546798029556\n",
            "f1score_true: 0.6589861751152073\n",
            "f1score_fake: 0.612565445026178\n",
            "Binary_loss 1.0062395\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6176470588235294\n",
            "precision_true: 0.5897435897435898\n",
            "precision_fake: 0.674074074074074\n",
            "recall_true: 0.7853658536585366\n",
            "recall_fake: 0.4482758620689655\n",
            "f1score_true: 0.6736401673640169\n",
            "f1score_fake: 0.5384615384615384\n",
            "Binary_loss 0.74106395\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 25\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6421568627450981\n",
            "precision_true: 0.642512077294686\n",
            "precision_fake: 0.6417910447761194\n",
            "recall_true: 0.6487804878048781\n",
            "recall_fake: 0.6354679802955665\n",
            "f1score_true: 0.6456310679611651\n",
            "f1score_fake: 0.6386138613861385\n",
            "Binary_loss 1.0567986\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6151960784313726\n",
            "precision_true: 0.5909090909090909\n",
            "precision_fake: 0.6597222222222222\n",
            "recall_true: 0.7609756097560976\n",
            "recall_fake: 0.46798029556650245\n",
            "f1score_true: 0.6652452025586354\n",
            "f1score_fake: 0.5475504322766571\n",
            "Binary_loss 0.78518724\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.660024906600249\n",
            "precision_true: 0.6888888888888889\n",
            "precision_fake: 0.6306532663316583\n",
            "recall_true: 0.6549295774647887\n",
            "recall_fake: 0.6657824933687002\n",
            "f1score_true: 0.6714801444043321\n",
            "f1score_fake: 0.6477419354838709\n",
            "Binary_loss 0.90956295\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6924034869240349\n",
            "precision_true: 0.6731141199226306\n",
            "precision_fake: 0.7272727272727273\n",
            "recall_true: 0.8169014084507042\n",
            "recall_fake: 0.5517241379310345\n",
            "f1score_true: 0.7380699893955461\n",
            "f1score_fake: 0.6274509803921569\n",
            "Binary_loss 0.66704404\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 26\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6323529411764706\n",
            "precision_true: 0.6729559748427673\n",
            "precision_fake: 0.606425702811245\n",
            "recall_true: 0.5219512195121951\n",
            "recall_fake: 0.7438423645320197\n",
            "f1score_true: 0.5879120879120878\n",
            "f1score_fake: 0.668141592920354\n",
            "Binary_loss 1.0824809\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6274509803921569\n",
            "precision_true: 0.603112840466926\n",
            "precision_fake: 0.6688741721854304\n",
            "recall_true: 0.7560975609756098\n",
            "recall_fake: 0.4975369458128079\n",
            "f1score_true: 0.670995670995671\n",
            "f1score_fake: 0.5706214689265536\n",
            "Binary_loss 0.83678436\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 27\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.5709779179810726\n",
            "precision_fake: 0.7362637362637363\n",
            "recall_true: 0.8829268292682927\n",
            "recall_fake: 0.33004926108374383\n",
            "f1score_true: 0.6934865900383141\n",
            "f1score_fake: 0.4557823129251701\n",
            "Binary_loss 1.4651372\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6274509803921569\n",
            "precision_true: 0.6047430830039525\n",
            "precision_fake: 0.6645161290322581\n",
            "recall_true: 0.7463414634146341\n",
            "recall_fake: 0.5073891625615764\n",
            "f1score_true: 0.6681222707423581\n",
            "f1score_fake: 0.5754189944134078\n",
            "Binary_loss 0.87198013\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 28\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.6476683937823834\n",
            "precision_fake: 0.627906976744186\n",
            "recall_true: 0.6097560975609756\n",
            "recall_fake: 0.6650246305418719\n",
            "f1score_true: 0.6281407035175879\n",
            "f1score_fake: 0.645933014354067\n",
            "Binary_loss 0.9582362\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6397058823529411\n",
            "precision_true: 0.6198347107438017\n",
            "precision_fake: 0.6686746987951807\n",
            "recall_true: 0.7317073170731707\n",
            "recall_fake: 0.5467980295566502\n",
            "f1score_true: 0.6711409395973154\n",
            "f1score_fake: 0.6016260162601625\n",
            "Binary_loss 0.88956046\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 29\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6323529411764706\n",
            "precision_true: 0.6870748299319728\n",
            "precision_fake: 0.6015325670498084\n",
            "recall_true: 0.4926829268292683\n",
            "recall_fake: 0.7733990147783252\n",
            "f1score_true: 0.5738636363636362\n",
            "f1score_fake: 0.6767241379310345\n",
            "Binary_loss 1.3848244\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6470588235294118\n",
            "precision_true: 0.6367713004484304\n",
            "precision_fake: 0.6594594594594595\n",
            "recall_true: 0.6926829268292682\n",
            "recall_fake: 0.6009852216748769\n",
            "f1score_true: 0.663551401869159\n",
            "f1score_fake: 0.6288659793814434\n",
            "Binary_loss 0.91472626\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 30\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6127450980392157\n",
            "precision_true: 0.6205128205128205\n",
            "precision_fake: 0.6056338028169014\n",
            "recall_true: 0.5902439024390244\n",
            "recall_fake: 0.6354679802955665\n",
            "f1score_true: 0.6049999999999999\n",
            "f1score_fake: 0.6201923076923077\n",
            "Binary_loss 1.4122308\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6348039215686274\n",
            "precision_true: 0.6386138613861386\n",
            "precision_fake: 0.6310679611650486\n",
            "recall_true: 0.6292682926829268\n",
            "recall_fake: 0.6403940886699507\n",
            "f1score_true: 0.6339066339066339\n",
            "f1score_fake: 0.6356968215158925\n",
            "Binary_loss 0.9629977\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6625155666251556\n",
            "precision_true: 0.7002583979328165\n",
            "precision_fake: 0.6274038461538461\n",
            "recall_true: 0.636150234741784\n",
            "recall_fake: 0.6923076923076923\n",
            "f1score_true: 0.6666666666666666\n",
            "f1score_fake: 0.6582597730138714\n",
            "Binary_loss 1.2269055\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6662515566625156\n",
            "precision_true: 0.7046632124352331\n",
            "precision_fake: 0.6306954436450839\n",
            "recall_true: 0.6384976525821596\n",
            "recall_fake: 0.6976127320954907\n",
            "f1score_true: 0.6699507389162561\n",
            "f1score_fake: 0.6624685138539043\n",
            "Binary_loss 0.78266907\n",
            "-----------------------------------------------------------------\n",
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 816 814\n",
            "Test Label count : True, Fake 443 360\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 429ms/step - loss: 0.6930 - accuracy: 0.5155\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.69270146\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.69273704\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 2\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.6920105\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.69291097\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 3\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.69140446\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.6929661\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 4\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5220588235294118\n",
            "precision_true: 0.6585365853658537\n",
            "precision_fake: 0.5068119891008175\n",
            "recall_true: 0.12980769230769232\n",
            "recall_fake: 0.93\n",
            "f1score_true: 0.2168674698795181\n",
            "f1score_fake: 0.6560846560846562\n",
            "Binary_loss 0.69048613\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.692909\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 5\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5269607843137255\n",
            "precision_true: 0.6530612244897959\n",
            "precision_fake: 0.5097493036211699\n",
            "recall_true: 0.15384615384615385\n",
            "recall_fake: 0.915\n",
            "f1score_true: 0.2490272373540856\n",
            "f1score_fake: 0.6547406082289803\n",
            "Binary_loss 0.68909013\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.6927352\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 6\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5441176470588235\n",
            "precision_true: 0.627906976744186\n",
            "precision_fake: 0.5217391304347826\n",
            "recall_true: 0.25961538461538464\n",
            "recall_fake: 0.84\n",
            "f1score_true: 0.3673469387755103\n",
            "f1score_fake: 0.6436781609195402\n",
            "Binary_loss 0.68608975\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.6924075\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 7\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5416666666666666\n",
            "precision_true: 0.64\n",
            "precision_fake: 0.5195195195195195\n",
            "recall_true: 0.23076923076923078\n",
            "recall_fake: 0.865\n",
            "f1score_true: 0.3392226148409894\n",
            "f1score_fake: 0.649155722326454\n",
            "Binary_loss 0.6798838\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.69183797\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 8\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6029411764705882\n",
            "precision_true: 0.5833333333333334\n",
            "precision_fake: 0.6439393939393939\n",
            "recall_true: 0.7740384615384616\n",
            "recall_fake: 0.425\n",
            "f1score_true: 0.6652892561983471\n",
            "f1score_fake: 0.5120481927710844\n",
            "Binary_loss 0.6469453\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49019607843137253\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49019607843137253\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6578947368421052\n",
            "Binary_loss 0.6909259\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 9\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5784313725490197\n",
            "precision_true: 0.5555555555555556\n",
            "precision_fake: 0.6666666666666666\n",
            "recall_true: 0.8653846153846154\n",
            "recall_fake: 0.28\n",
            "f1score_true: 0.6766917293233082\n",
            "f1score_fake: 0.3943661971830986\n",
            "Binary_loss 0.6479548\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4852941176470588\n",
            "precision_true: 0.25\n",
            "precision_fake: 0.4876237623762376\n",
            "recall_true: 0.004807692307692308\n",
            "recall_fake: 0.985\n",
            "f1score_true: 0.009433962264150945\n",
            "f1score_fake: 0.652317880794702\n",
            "Binary_loss 0.6895761\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 10\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5759803921568627\n",
            "precision_true: 0.5879396984924623\n",
            "precision_fake: 0.5645933014354066\n",
            "recall_true: 0.5625\n",
            "recall_fake: 0.59\n",
            "f1score_true: 0.5749385749385749\n",
            "f1score_fake: 0.5770171149144254\n",
            "Binary_loss 0.7953153\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4877450980392157\n",
            "precision_true: 0.42857142857142855\n",
            "precision_fake: 0.48877805486284287\n",
            "recall_true: 0.014423076923076924\n",
            "recall_fake: 0.98\n",
            "f1score_true: 0.027906976744186046\n",
            "f1score_fake: 0.6522462562396006\n",
            "Binary_loss 0.6878891\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6176836861768369\n",
            "precision_true: 0.673469387755102\n",
            "precision_fake: 0.5644768856447688\n",
            "recall_true: 0.5959367945823928\n",
            "recall_fake: 0.6444444444444445\n",
            "f1score_true: 0.6323353293413173\n",
            "f1score_fake: 0.6018158236057068\n",
            "Binary_loss 0.73998934\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.4669987546699875\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.45685279187817257\n",
            "recall_true: 0.033860045146726865\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.06550218340611355\n",
            "f1score_fake: 0.627177700348432\n",
            "Binary_loss 0.68779\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 11\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6176470588235294\n",
            "precision_true: 0.6150442477876106\n",
            "precision_fake: 0.6208791208791209\n",
            "recall_true: 0.6682692307692307\n",
            "recall_fake: 0.565\n",
            "f1score_true: 0.640552995391705\n",
            "f1score_fake: 0.5916230366492147\n",
            "Binary_loss 0.7130655\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5024509803921569\n",
            "precision_true: 0.6666666666666666\n",
            "precision_fake: 0.4961832061068702\n",
            "recall_true: 0.04807692307692308\n",
            "recall_fake: 0.975\n",
            "f1score_true: 0.08968609865470852\n",
            "f1score_fake: 0.657672849915683\n",
            "Binary_loss 0.6857728\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 12\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.6339285714285714\n",
            "precision_fake: 0.6413043478260869\n",
            "recall_true: 0.6826923076923077\n",
            "recall_fake: 0.59\n",
            "f1score_true: 0.6574074074074074\n",
            "f1score_fake: 0.6145833333333333\n",
            "Binary_loss 0.70398486\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5343137254901961\n",
            "precision_true: 0.8\n",
            "precision_fake: 0.5132275132275133\n",
            "recall_true: 0.11538461538461539\n",
            "recall_fake: 0.97\n",
            "f1score_true: 0.20168067226890757\n",
            "f1score_fake: 0.6712802768166091\n",
            "Binary_loss 0.68291837\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 13\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6348039215686274\n",
            "precision_true: 0.7153284671532847\n",
            "precision_fake: 0.5940959409594095\n",
            "recall_true: 0.47115384615384615\n",
            "recall_fake: 0.805\n",
            "f1score_true: 0.5681159420289855\n",
            "f1score_fake: 0.683651804670913\n",
            "Binary_loss 0.6859823\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5367647058823529\n",
            "precision_true: 0.7567567567567568\n",
            "precision_fake: 0.5148247978436657\n",
            "recall_true: 0.1346153846153846\n",
            "recall_fake: 0.955\n",
            "f1score_true: 0.2285714285714286\n",
            "f1score_fake: 0.669001751313485\n",
            "Binary_loss 0.6788987\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 14\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.7338129496402878\n",
            "precision_fake: 0.6059479553903345\n",
            "recall_true: 0.49038461538461536\n",
            "recall_fake: 0.815\n",
            "f1score_true: 0.5878962536023055\n",
            "f1score_fake: 0.6950959488272921\n",
            "Binary_loss 0.7147385\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5514705882352942\n",
            "precision_true: 0.6984126984126984\n",
            "precision_fake: 0.5246376811594203\n",
            "recall_true: 0.21153846153846154\n",
            "recall_fake: 0.905\n",
            "f1score_true: 0.3247232472324723\n",
            "f1score_fake: 0.6642201834862385\n",
            "Binary_loss 0.67288315\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 15\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6004901960784313\n",
            "precision_true: 0.5675675675675675\n",
            "precision_fake: 0.7466666666666667\n",
            "recall_true: 0.9086538461538461\n",
            "recall_fake: 0.28\n",
            "f1score_true: 0.6987060998151571\n",
            "f1score_fake: 0.4072727272727273\n",
            "Binary_loss 0.7827941\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5955882352941176\n",
            "precision_true: 0.7362637362637363\n",
            "precision_fake: 0.555205047318612\n",
            "recall_true: 0.32211538461538464\n",
            "recall_fake: 0.88\n",
            "f1score_true: 0.44816053511705695\n",
            "f1score_fake: 0.6808510638297872\n",
            "Binary_loss 0.662933\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6712328767123288\n",
            "precision_true: 0.6422893481717011\n",
            "precision_fake: 0.7758620689655172\n",
            "recall_true: 0.9119638826185101\n",
            "recall_fake: 0.375\n",
            "f1score_true: 0.7537313432835822\n",
            "f1score_fake: 0.5056179775280898\n",
            "Binary_loss 0.66128063\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6064757160647571\n",
            "precision_true: 0.8670520231213873\n",
            "precision_fake: 0.5349206349206349\n",
            "recall_true: 0.33860045146726864\n",
            "recall_fake: 0.9361111111111111\n",
            "f1score_true: 0.48701298701298706\n",
            "f1score_fake: 0.6808080808080809\n",
            "Binary_loss 0.6608199\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 16\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6274509803921569\n",
            "precision_true: 0.5864197530864198\n",
            "precision_fake: 0.7857142857142857\n",
            "recall_true: 0.9134615384615384\n",
            "recall_fake: 0.33\n",
            "f1score_true: 0.7142857142857143\n",
            "f1score_fake: 0.46478873239436624\n",
            "Binary_loss 0.7697859\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6151960784313726\n",
            "precision_true: 0.7475728155339806\n",
            "precision_fake: 0.5704918032786885\n",
            "recall_true: 0.3701923076923077\n",
            "recall_fake: 0.87\n",
            "f1score_true: 0.4951768488745981\n",
            "f1score_fake: 0.689108910891089\n",
            "Binary_loss 0.64822817\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 17\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6577777777777778\n",
            "precision_fake: 0.6721311475409836\n",
            "recall_true: 0.7115384615384616\n",
            "recall_fake: 0.615\n",
            "f1score_true: 0.6836027713625866\n",
            "f1score_fake: 0.6422976501305484\n",
            "Binary_loss 0.732912\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6225490196078431\n",
            "precision_true: 0.75\n",
            "precision_fake: 0.5766666666666667\n",
            "recall_true: 0.3894230769230769\n",
            "recall_fake: 0.865\n",
            "f1score_true: 0.5126582278481013\n",
            "f1score_fake: 0.692\n",
            "Binary_loss 0.6301458\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 18\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6468085106382979\n",
            "precision_fake: 0.6763005780346821\n",
            "recall_true: 0.7307692307692307\n",
            "recall_fake: 0.585\n",
            "f1score_true: 0.6862302483069977\n",
            "f1score_fake: 0.6273458445040214\n",
            "Binary_loss 0.8182203\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6151960784313726\n",
            "precision_true: 0.7524752475247525\n",
            "precision_fake: 0.5700325732899023\n",
            "recall_true: 0.36538461538461536\n",
            "recall_fake: 0.875\n",
            "f1score_true: 0.49190938511326854\n",
            "f1score_fake: 0.6903353057199212\n",
            "Binary_loss 0.6164624\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 19\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.64453125\n",
            "precision_fake: 0.7171052631578947\n",
            "recall_true: 0.7932692307692307\n",
            "recall_fake: 0.545\n",
            "f1score_true: 0.7112068965517241\n",
            "f1score_fake: 0.6193181818181819\n",
            "Binary_loss 0.8166655\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6102941176470589\n",
            "precision_true: 0.7951807228915663\n",
            "precision_fake: 0.563076923076923\n",
            "recall_true: 0.3173076923076923\n",
            "recall_fake: 0.915\n",
            "f1score_true: 0.4536082474226804\n",
            "f1score_fake: 0.6971428571428572\n",
            "Binary_loss 0.6144087\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 20\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.65625\n",
            "precision_fake: 0.6684782608695652\n",
            "recall_true: 0.7067307692307693\n",
            "recall_fake: 0.615\n",
            "f1score_true: 0.6805555555555557\n",
            "f1score_fake: 0.640625\n",
            "Binary_loss 0.9311884\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.8428571428571429\n",
            "precision_fake: 0.5591715976331361\n",
            "recall_true: 0.28365384615384615\n",
            "recall_fake: 0.945\n",
            "f1score_true: 0.42446043165467623\n",
            "f1score_fake: 0.7026022304832714\n",
            "Binary_loss 0.6208408\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6911581569115816\n",
            "precision_true: 0.7349397590361446\n",
            "precision_fake: 0.6443298969072165\n",
            "recall_true: 0.6884875846501128\n",
            "recall_fake: 0.6944444444444444\n",
            "f1score_true: 0.710955710955711\n",
            "f1score_fake: 0.6684491978609626\n",
            "Binary_loss 0.9158742\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6064757160647571\n",
            "precision_true: 0.9319727891156463\n",
            "precision_fake: 0.5335365853658537\n",
            "recall_true: 0.309255079006772\n",
            "recall_fake: 0.9722222222222222\n",
            "f1score_true: 0.464406779661017\n",
            "f1score_fake: 0.6889763779527559\n",
            "Binary_loss 0.6166363\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 21\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6403162055335968\n",
            "precision_fake: 0.7032258064516129\n",
            "recall_true: 0.7788461538461539\n",
            "recall_fake: 0.545\n",
            "f1score_true: 0.702819956616052\n",
            "f1score_fake: 0.6140845070422536\n",
            "Binary_loss 0.95167345\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.8243243243243243\n",
            "precision_fake: 0.5598802395209581\n",
            "recall_true: 0.2932692307692308\n",
            "recall_fake: 0.935\n",
            "f1score_true: 0.4326241134751773\n",
            "f1score_fake: 0.7003745318352059\n",
            "Binary_loss 0.63040656\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 22\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6544117647058824\n",
            "precision_true: 0.6334661354581673\n",
            "precision_fake: 0.6878980891719745\n",
            "recall_true: 0.7644230769230769\n",
            "recall_fake: 0.54\n",
            "f1score_true: 0.6928104575163399\n",
            "f1score_fake: 0.6050420168067228\n",
            "Binary_loss 1.037705\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.7941176470588235\n",
            "precision_fake: 0.5849673202614379\n",
            "recall_true: 0.3894230769230769\n",
            "recall_fake: 0.895\n",
            "f1score_true: 0.5225806451612903\n",
            "f1score_fake: 0.7075098814229249\n",
            "Binary_loss 0.6430926\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 23\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6568627450980392\n",
            "precision_true: 0.6416666666666667\n",
            "precision_fake: 0.6785714285714286\n",
            "recall_true: 0.7403846153846154\n",
            "recall_fake: 0.57\n",
            "f1score_true: 0.6875000000000001\n",
            "f1score_fake: 0.6195652173913043\n",
            "Binary_loss 1.086117\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.7238805970149254\n",
            "precision_fake: 0.5948905109489051\n",
            "recall_true: 0.46634615384615385\n",
            "recall_fake: 0.815\n",
            "f1score_true: 0.5672514619883042\n",
            "f1score_fake: 0.6877637130801687\n",
            "Binary_loss 0.65930253\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 24\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.676056338028169\n",
            "precision_fake: 0.6717948717948717\n",
            "recall_true: 0.6923076923076923\n",
            "recall_fake: 0.655\n",
            "f1score_true: 0.684085510688836\n",
            "f1score_fake: 0.6632911392405063\n",
            "Binary_loss 1.0359173\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6666666666666666\n",
            "precision_true: 0.7337662337662337\n",
            "precision_fake: 0.6259842519685039\n",
            "recall_true: 0.5432692307692307\n",
            "recall_fake: 0.795\n",
            "f1score_true: 0.6243093922651933\n",
            "f1score_fake: 0.7004405286343612\n",
            "Binary_loss 0.67464864\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 25\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.663594470046083\n",
            "precision_fake: 0.6649214659685864\n",
            "recall_true: 0.6923076923076923\n",
            "recall_fake: 0.635\n",
            "f1score_true: 0.6776470588235294\n",
            "f1score_fake: 0.6496163682864451\n",
            "Binary_loss 1.1364014\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.7175141242937854\n",
            "precision_fake: 0.6493506493506493\n",
            "recall_true: 0.6105769230769231\n",
            "recall_fake: 0.75\n",
            "f1score_true: 0.6597402597402598\n",
            "f1score_fake: 0.6960556844547564\n",
            "Binary_loss 0.70683604\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.684931506849315\n",
            "precision_true: 0.7328431372549019\n",
            "precision_fake: 0.6354430379746835\n",
            "recall_true: 0.6749435665914221\n",
            "recall_fake: 0.6972222222222222\n",
            "f1score_true: 0.7027027027027026\n",
            "f1score_fake: 0.6649006622516554\n",
            "Binary_loss 1.0908557\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6625155666251556\n",
            "precision_true: 0.76875\n",
            "precision_fake: 0.5921325051759835\n",
            "recall_true: 0.5553047404063205\n",
            "recall_fake: 0.7944444444444444\n",
            "f1score_true: 0.6448230668414154\n",
            "f1score_fake: 0.6785290628706998\n",
            "Binary_loss 0.6941462\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 26\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.6746411483253588\n",
            "precision_fake: 0.6633165829145728\n",
            "recall_true: 0.6778846153846154\n",
            "recall_fake: 0.66\n",
            "f1score_true: 0.6762589928057553\n",
            "f1score_fake: 0.6616541353383459\n",
            "Binary_loss 1.2038511\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.6919191919191919\n",
            "precision_fake: 0.6619047619047619\n",
            "recall_true: 0.6586538461538461\n",
            "recall_fake: 0.695\n",
            "f1score_true: 0.6748768472906403\n",
            "f1score_fake: 0.6780487804878049\n",
            "Binary_loss 0.7512965\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 27\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6544117647058824\n",
            "precision_true: 0.6475770925110133\n",
            "precision_fake: 0.6629834254143646\n",
            "recall_true: 0.7067307692307693\n",
            "recall_fake: 0.6\n",
            "f1score_true: 0.6758620689655173\n",
            "f1score_fake: 0.6299212598425197\n",
            "Binary_loss 1.2295729\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.6811594202898551\n",
            "precision_fake: 0.6666666666666666\n",
            "recall_true: 0.6778846153846154\n",
            "recall_fake: 0.67\n",
            "f1score_true: 0.6795180722891567\n",
            "f1score_fake: 0.6683291770573566\n",
            "Binary_loss 0.80112547\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 28\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.642570281124498\n",
            "precision_fake: 0.6981132075471698\n",
            "recall_true: 0.7692307692307693\n",
            "recall_fake: 0.555\n",
            "f1score_true: 0.7002188183807441\n",
            "f1score_fake: 0.6183844011142061\n",
            "Binary_loss 1.2545084\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6807511737089202\n",
            "precision_fake: 0.676923076923077\n",
            "recall_true: 0.6971153846153846\n",
            "recall_fake: 0.66\n",
            "f1score_true: 0.6888361045130641\n",
            "f1score_fake: 0.668354430379747\n",
            "Binary_loss 0.8440212\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 29\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.6622222222222223\n",
            "precision_fake: 0.6775956284153005\n",
            "recall_true: 0.7163461538461539\n",
            "recall_fake: 0.62\n",
            "f1score_true: 0.6882217090069285\n",
            "f1score_fake: 0.6475195822454308\n",
            "Binary_loss 1.2736706\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.6759259259259259\n",
            "precision_fake: 0.6770833333333334\n",
            "recall_true: 0.7019230769230769\n",
            "recall_fake: 0.65\n",
            "f1score_true: 0.6886792452830189\n",
            "f1score_fake: 0.6632653061224489\n",
            "Binary_loss 0.9054131\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 30\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6455696202531646\n",
            "precision_fake: 0.6783625730994152\n",
            "recall_true: 0.7355769230769231\n",
            "recall_fake: 0.58\n",
            "f1score_true: 0.6876404494382022\n",
            "f1score_fake: 0.6253369272237197\n",
            "Binary_loss 1.2168695\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.6697247706422018\n",
            "precision_fake: 0.6736842105263158\n",
            "recall_true: 0.7019230769230769\n",
            "recall_fake: 0.64\n",
            "f1score_true: 0.6854460093896714\n",
            "f1score_fake: 0.6564102564102564\n",
            "Binary_loss 0.9570274\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6973848069738481\n",
            "precision_true: 0.7202643171806168\n",
            "precision_fake: 0.667621776504298\n",
            "recall_true: 0.7381489841986456\n",
            "recall_fake: 0.6472222222222223\n",
            "f1score_true: 0.7290969899665553\n",
            "f1score_fake: 0.6572637517630465\n",
            "Binary_loss 1.143747\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6998754669987547\n",
            "precision_true: 0.7451456310679612\n",
            "precision_fake: 0.6521739130434783\n",
            "recall_true: 0.6930022573363431\n",
            "recall_fake: 0.7083333333333334\n",
            "f1score_true: 0.7181286549707603\n",
            "f1score_fake: 0.6790945406125167\n",
            "Binary_loss 0.9174151\n",
            "-----------------------------------------------------------------\n",
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 842 788\n",
            "Test Label count : True, Fake 417 386\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 430ms/step - loss: 0.6924 - accuracy: 0.5295\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.553921568627451\n",
            "precision_true: 0.5732484076433121\n",
            "precision_fake: 0.5418326693227091\n",
            "recall_true: 0.43902439024390244\n",
            "recall_fake: 0.6699507389162561\n",
            "f1score_true: 0.49723756906077343\n",
            "f1score_fake: 0.5991189427312774\n",
            "Binary_loss 0.6915847\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5245098039215687\n",
            "precision_true: 0.5217391304347826\n",
            "precision_fake: 0.5290322580645161\n",
            "recall_true: 0.6439024390243903\n",
            "recall_fake: 0.4039408866995074\n",
            "f1score_true: 0.576419213973799\n",
            "f1score_fake: 0.45810055865921795\n",
            "Binary_loss 0.69251865\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 2\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5808823529411765\n",
            "precision_true: 0.5508982035928144\n",
            "precision_fake: 0.7162162162162162\n",
            "recall_true: 0.8975609756097561\n",
            "recall_fake: 0.26108374384236455\n",
            "f1score_true: 0.6827458256029685\n",
            "f1score_fake: 0.38267148014440433\n",
            "Binary_loss 0.69060624\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4950980392156863\n",
            "precision_true: 0.4\n",
            "precision_fake: 0.49627791563275436\n",
            "recall_true: 0.00975609756097561\n",
            "recall_fake: 0.9852216748768473\n",
            "f1score_true: 0.019047619047619046\n",
            "f1score_fake: 0.6600660066006602\n",
            "Binary_loss 0.69277924\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 3\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.5786163522012578\n",
            "precision_fake: 0.7666666666666667\n",
            "recall_true: 0.8975609756097561\n",
            "recall_fake: 0.3399014778325123\n",
            "f1score_true: 0.7036328871892925\n",
            "f1score_fake: 0.4709897610921501\n",
            "Binary_loss 0.68923944\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49754901960784315\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6644844517184942\n",
            "Binary_loss 0.6927584\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 4\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6127450980392157\n",
            "precision_true: 0.56657223796034\n",
            "precision_fake: 0.9090909090909091\n",
            "recall_true: 0.975609756097561\n",
            "recall_fake: 0.24630541871921183\n",
            "f1score_true: 0.7168458781362008\n",
            "f1score_fake: 0.3875968992248062\n",
            "Binary_loss 0.68736655\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.49754901960784315\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6644844517184942\n",
            "Binary_loss 0.6925044\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 5\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6544117647058824\n",
            "precision_true: 0.6012658227848101\n",
            "precision_fake: 0.8369565217391305\n",
            "recall_true: 0.926829268292683\n",
            "recall_fake: 0.3793103448275862\n",
            "f1score_true: 0.7293666026871402\n",
            "f1score_fake: 0.5220338983050847\n",
            "Binary_loss 0.6832324\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5465686274509803\n",
            "precision_true: 0.75\n",
            "precision_fake: 0.5244565217391305\n",
            "recall_true: 0.14634146341463414\n",
            "recall_fake: 0.9507389162561576\n",
            "f1score_true: 0.24489795918367344\n",
            "f1score_fake: 0.6760070052539404\n",
            "Binary_loss 0.6920099\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 6\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6446078431372549\n",
            "precision_true: 0.5980392156862745\n",
            "precision_fake: 0.7843137254901961\n",
            "recall_true: 0.8926829268292683\n",
            "recall_fake: 0.39408866995073893\n",
            "f1score_true: 0.7162426614481409\n",
            "f1score_fake: 0.5245901639344263\n",
            "Binary_loss 0.6707991\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5808823529411765\n",
            "precision_true: 0.646551724137931\n",
            "precision_fake: 0.5547945205479452\n",
            "recall_true: 0.36585365853658536\n",
            "recall_fake: 0.7980295566502463\n",
            "f1score_true: 0.4672897196261683\n",
            "f1score_fake: 0.6545454545454547\n",
            "Binary_loss 0.6911856\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 7\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6397058823529411\n",
            "precision_true: 0.5900621118012422\n",
            "precision_fake: 0.8255813953488372\n",
            "recall_true: 0.926829268292683\n",
            "recall_fake: 0.3497536945812808\n",
            "f1score_true: 0.7210626185958254\n",
            "f1score_fake: 0.49134948096885817\n",
            "Binary_loss 0.64061755\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.6510067114093959\n",
            "precision_fake: 0.583011583011583\n",
            "recall_true: 0.47317073170731705\n",
            "recall_fake: 0.7438423645320197\n",
            "f1score_true: 0.5480225988700564\n",
            "f1score_fake: 0.6536796536796537\n",
            "Binary_loss 0.68983984\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 8\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.7840909090909091\n",
            "precision_fake: 0.575\n",
            "recall_true: 0.33658536585365856\n",
            "recall_fake: 0.9064039408866995\n",
            "f1score_true: 0.4709897610921502\n",
            "f1score_fake: 0.7036328871892925\n",
            "Binary_loss 0.62403077\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.7050359712230215\n",
            "precision_fake: 0.6022304832713755\n",
            "recall_true: 0.47804878048780486\n",
            "recall_fake: 0.7980295566502463\n",
            "f1score_true: 0.569767441860465\n",
            "f1score_fake: 0.6864406779661018\n",
            "Binary_loss 0.687805\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 9\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6176470588235294\n",
            "precision_true: 0.7378640776699029\n",
            "precision_fake: 0.5770491803278689\n",
            "recall_true: 0.37073170731707317\n",
            "recall_fake: 0.8669950738916257\n",
            "f1score_true: 0.4935064935064935\n",
            "f1score_fake: 0.6929133858267716\n",
            "Binary_loss 0.65510213\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.752\n",
            "precision_fake: 0.607773851590106\n",
            "recall_true: 0.4585365853658537\n",
            "recall_fake: 0.8472906403940886\n",
            "f1score_true: 0.5696969696969697\n",
            "f1score_fake: 0.7078189300411522\n",
            "Binary_loss 0.6848702\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 10\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6225490196078431\n",
            "precision_true: 0.7142857142857143\n",
            "precision_fake: 0.5847750865051903\n",
            "recall_true: 0.4146341463414634\n",
            "recall_fake: 0.8325123152709359\n",
            "f1score_true: 0.5246913580246914\n",
            "f1score_fake: 0.6869918699186992\n",
            "Binary_loss 0.61552566\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.7846153846153846\n",
            "precision_fake: 0.6294964028776978\n",
            "recall_true: 0.4975609756097561\n",
            "recall_fake: 0.8620689655172413\n",
            "f1score_true: 0.608955223880597\n",
            "f1score_fake: 0.7276507276507276\n",
            "Binary_loss 0.68080485\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.5952677459526775\n",
            "precision_true: 0.7169811320754716\n",
            "precision_fake: 0.5516074450084603\n",
            "recall_true: 0.3645083932853717\n",
            "recall_fake: 0.844559585492228\n",
            "f1score_true: 0.48330683624801274\n",
            "f1score_fake: 0.6673490276356192\n",
            "Binary_loss 0.6502776\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6151930261519303\n",
            "precision_true: 0.716\n",
            "precision_fake: 0.569620253164557\n",
            "recall_true: 0.4292565947242206\n",
            "recall_fake: 0.8160621761658031\n",
            "f1score_true: 0.5367316341829085\n",
            "f1score_fake: 0.6709265175718849\n",
            "Binary_loss 0.6832965\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 11\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6213235294117647\n",
            "precision_fake: 0.7352941176470589\n",
            "recall_true: 0.824390243902439\n",
            "recall_fake: 0.49261083743842365\n",
            "f1score_true: 0.7085953878406708\n",
            "f1score_fake: 0.5899705014749262\n",
            "Binary_loss 0.64707917\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6666666666666666\n",
            "precision_true: 0.7446808510638298\n",
            "precision_fake: 0.6254681647940075\n",
            "recall_true: 0.5121951219512195\n",
            "recall_fake: 0.8226600985221675\n",
            "f1score_true: 0.6069364161849711\n",
            "f1score_fake: 0.7106382978723405\n",
            "Binary_loss 0.67517436\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 12\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6397058823529411\n",
            "precision_true: 0.5868263473053892\n",
            "precision_fake: 0.8783783783783784\n",
            "recall_true: 0.9560975609756097\n",
            "recall_fake: 0.32019704433497537\n",
            "f1score_true: 0.7272727272727272\n",
            "f1score_fake: 0.4693140794223827\n",
            "Binary_loss 1.2612593\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.7605633802816901\n",
            "precision_fake: 0.6353383458646616\n",
            "recall_true: 0.526829268292683\n",
            "recall_fake: 0.8325123152709359\n",
            "f1score_true: 0.622478386167147\n",
            "f1score_fake: 0.720682302771855\n",
            "Binary_loss 0.6674666\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 13\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.7627118644067796\n",
            "precision_fake: 0.603448275862069\n",
            "recall_true: 0.43902439024390244\n",
            "recall_fake: 0.8620689655172413\n",
            "f1score_true: 0.5572755417956657\n",
            "f1score_fake: 0.7099391480730223\n",
            "Binary_loss 0.62282336\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6421568627450981\n",
            "precision_true: 0.7610619469026548\n",
            "precision_fake: 0.5966101694915255\n",
            "recall_true: 0.4195121951219512\n",
            "recall_fake: 0.8669950738916257\n",
            "f1score_true: 0.540880503144654\n",
            "f1score_fake: 0.7068273092369478\n",
            "Binary_loss 0.65964925\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 14\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6745283018867925\n",
            "precision_fake: 0.6836734693877551\n",
            "recall_true: 0.697560975609756\n",
            "recall_fake: 0.6600985221674877\n",
            "f1score_true: 0.6858513189448441\n",
            "f1score_fake: 0.6716791979949875\n",
            "Binary_loss 0.6184588\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.7739130434782608\n",
            "precision_fake: 0.6040955631399317\n",
            "recall_true: 0.43414634146341463\n",
            "recall_fake: 0.8719211822660099\n",
            "f1score_true: 0.55625\n",
            "f1score_fake: 0.7137096774193549\n",
            "Binary_loss 0.6523484\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 15\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6666666666666666\n",
            "precision_true: 0.6533333333333333\n",
            "precision_fake: 0.6830601092896175\n",
            "recall_true: 0.7170731707317073\n",
            "recall_fake: 0.6157635467980296\n",
            "f1score_true: 0.6837209302325581\n",
            "f1score_fake: 0.6476683937823835\n",
            "Binary_loss 0.6153404\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.7441860465116279\n",
            "precision_fake: 0.6093189964157706\n",
            "recall_true: 0.4682926829268293\n",
            "recall_fake: 0.8374384236453202\n",
            "f1score_true: 0.5748502994011977\n",
            "f1score_fake: 0.7053941908713692\n",
            "Binary_loss 0.64319384\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.663760896637609\n",
            "precision_true: 0.6729411764705883\n",
            "precision_fake: 0.6534391534391535\n",
            "recall_true: 0.6858513189448441\n",
            "recall_fake: 0.6398963730569949\n",
            "f1score_true: 0.679334916864608\n",
            "f1score_fake: 0.6465968586387435\n",
            "Binary_loss 0.63919616\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6288916562889165\n",
            "precision_true: 0.7228464419475655\n",
            "precision_fake: 0.582089552238806\n",
            "recall_true: 0.4628297362110312\n",
            "recall_fake: 0.8082901554404145\n",
            "f1score_true: 0.564327485380117\n",
            "f1score_fake: 0.6767895878524947\n",
            "Binary_loss 0.6551212\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 16\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6446078431372549\n",
            "precision_true: 0.6162790697674418\n",
            "precision_fake: 0.6933333333333334\n",
            "recall_true: 0.775609756097561\n",
            "recall_fake: 0.5123152709359606\n",
            "f1score_true: 0.6868250539956804\n",
            "f1score_fake: 0.5892351274787535\n",
            "Binary_loss 0.99002665\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.7463768115942029\n",
            "precision_fake: 0.6222222222222222\n",
            "recall_true: 0.5024390243902439\n",
            "recall_fake: 0.8275862068965517\n",
            "f1score_true: 0.6005830903790087\n",
            "f1score_fake: 0.7103594080338267\n",
            "Binary_loss 0.6289578\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 17\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6410256410256411\n",
            "precision_fake: 0.6839080459770115\n",
            "recall_true: 0.7317073170731707\n",
            "recall_fake: 0.5862068965517241\n",
            "f1score_true: 0.683371298405467\n",
            "f1score_fake: 0.6312997347480107\n",
            "Binary_loss 1.0709085\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.7450980392156863\n",
            "precision_fake: 0.6431372549019608\n",
            "recall_true: 0.5560975609756098\n",
            "recall_fake: 0.8078817733990148\n",
            "f1score_true: 0.6368715083798884\n",
            "f1score_fake: 0.7161572052401748\n",
            "Binary_loss 0.6078133\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 18\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6544117647058824\n",
            "precision_true: 0.6126760563380281\n",
            "precision_fake: 0.75\n",
            "recall_true: 0.848780487804878\n",
            "recall_fake: 0.458128078817734\n",
            "f1score_true: 0.7116564417177913\n",
            "f1score_fake: 0.5688073394495413\n",
            "Binary_loss 1.1094295\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.7151898734177216\n",
            "precision_fake: 0.632\n",
            "recall_true: 0.551219512195122\n",
            "recall_fake: 0.7783251231527094\n",
            "f1score_true: 0.6225895316804408\n",
            "f1score_fake: 0.6975717439293598\n",
            "Binary_loss 0.5932437\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 19\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.669683257918552\n",
            "precision_fake: 0.6951871657754011\n",
            "recall_true: 0.7219512195121951\n",
            "recall_fake: 0.6403940886699507\n",
            "f1score_true: 0.6948356807511736\n",
            "f1score_fake: 0.6666666666666666\n",
            "Binary_loss 1.0564826\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.6981132075471698\n",
            "precision_fake: 0.6224899598393574\n",
            "recall_true: 0.5414634146341464\n",
            "recall_fake: 0.7635467980295566\n",
            "f1score_true: 0.6098901098901098\n",
            "f1score_fake: 0.6858407079646017\n",
            "Binary_loss 0.61815417\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 20\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.6802030456852792\n",
            "precision_fake: 0.6635071090047393\n",
            "recall_true: 0.6536585365853659\n",
            "recall_fake: 0.6896551724137931\n",
            "f1score_true: 0.6666666666666666\n",
            "f1score_fake: 0.6763285024154589\n",
            "Binary_loss 0.9889804\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.7032258064516129\n",
            "precision_fake: 0.6205533596837944\n",
            "recall_true: 0.5317073170731708\n",
            "recall_fake: 0.7733990147783252\n",
            "f1score_true: 0.6055555555555556\n",
            "f1score_fake: 0.6885964912280702\n",
            "Binary_loss 0.6937981\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6562889165628891\n",
            "precision_true: 0.6723716381418093\n",
            "precision_fake: 0.6395939086294417\n",
            "recall_true: 0.6594724220623501\n",
            "recall_fake: 0.6528497409326425\n",
            "f1score_true: 0.665859564164649\n",
            "f1score_fake: 0.6461538461538462\n",
            "Binary_loss 0.9984711\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6313823163138231\n",
            "precision_true: 0.6763848396501457\n",
            "precision_fake: 0.5978260869565217\n",
            "recall_true: 0.5563549160671463\n",
            "recall_fake: 0.7124352331606217\n",
            "f1score_true: 0.6105263157894737\n",
            "f1score_fake: 0.6501182033096926\n",
            "Binary_loss 0.7296938\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 21\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6330645161290323\n",
            "precision_fake: 0.7\n",
            "recall_true: 0.7658536585365854\n",
            "recall_fake: 0.5517241379310345\n",
            "f1score_true: 0.6931567328918322\n",
            "f1score_fake: 0.6170798898071626\n",
            "Binary_loss 0.96808577\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6470588235294118\n",
            "precision_true: 0.6942675159235668\n",
            "precision_fake: 0.6175298804780877\n",
            "recall_true: 0.5317073170731708\n",
            "recall_fake: 0.7635467980295566\n",
            "f1score_true: 0.6022099447513811\n",
            "f1score_fake: 0.6828193832599119\n",
            "Binary_loss 0.75506216\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 22\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.6620370370370371\n",
            "precision_fake: 0.6770833333333334\n",
            "recall_true: 0.697560975609756\n",
            "recall_fake: 0.6403940886699507\n",
            "f1score_true: 0.6793349168646082\n",
            "f1score_fake: 0.6582278481012659\n",
            "Binary_loss 1.0018269\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6544117647058824\n",
            "precision_true: 0.7\n",
            "precision_fake: 0.625\n",
            "recall_true: 0.5463414634146342\n",
            "recall_fake: 0.7635467980295566\n",
            "f1score_true: 0.6136986301369863\n",
            "f1score_fake: 0.6873614190687362\n",
            "Binary_loss 0.7954578\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 23\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.665158371040724\n",
            "precision_fake: 0.6898395721925134\n",
            "recall_true: 0.7170731707317073\n",
            "recall_fake: 0.6354679802955665\n",
            "f1score_true: 0.6901408450704225\n",
            "f1score_fake: 0.6615384615384615\n",
            "Binary_loss 0.9177355\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.7037037037037037\n",
            "precision_fake: 0.6300813008130082\n",
            "recall_true: 0.5560975609756098\n",
            "recall_fake: 0.7635467980295566\n",
            "f1score_true: 0.6212534059945505\n",
            "f1score_fake: 0.6904231625835189\n",
            "Binary_loss 0.82368636\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 24\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.632\n",
            "precision_fake: 0.7025316455696202\n",
            "recall_true: 0.7707317073170732\n",
            "recall_fake: 0.5467980295566502\n",
            "f1score_true: 0.6945054945054946\n",
            "f1score_fake: 0.6149584487534626\n",
            "Binary_loss 0.9310687\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.703030303030303\n",
            "precision_fake: 0.6337448559670782\n",
            "recall_true: 0.5658536585365853\n",
            "recall_fake: 0.7586206896551724\n",
            "f1score_true: 0.627027027027027\n",
            "f1score_fake: 0.6905829596412556\n",
            "Binary_loss 0.8280568\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 25\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.6510638297872341\n",
            "precision_fake: 0.6994219653179191\n",
            "recall_true: 0.7463414634146341\n",
            "recall_fake: 0.5960591133004927\n",
            "f1score_true: 0.6954545454545455\n",
            "f1score_fake: 0.6436170212765957\n",
            "Binary_loss 1.0302794\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6976744186046512\n",
            "precision_fake: 0.6398305084745762\n",
            "recall_true: 0.5853658536585366\n",
            "recall_fake: 0.7438423645320197\n",
            "f1score_true: 0.636604774535809\n",
            "f1score_fake: 0.6879271070615034\n",
            "Binary_loss 0.8481492\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6650062266500623\n",
            "precision_true: 0.6510204081632653\n",
            "precision_fake: 0.6869009584664537\n",
            "recall_true: 0.7649880095923262\n",
            "recall_fake: 0.5569948186528497\n",
            "f1score_true: 0.7034178610804851\n",
            "f1score_fake: 0.61516452074392\n",
            "Binary_loss 1.0535636\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.663760896637609\n",
            "precision_true: 0.6981132075471698\n",
            "precision_fake: 0.6342592592592593\n",
            "recall_true: 0.6211031175059952\n",
            "recall_fake: 0.7098445595854922\n",
            "f1score_true: 0.6573604060913706\n",
            "f1score_fake: 0.6699266503667481\n",
            "Binary_loss 0.8432126\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 26\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6341463414634146\n",
            "precision_fake: 0.6975308641975309\n",
            "recall_true: 0.7609756097560976\n",
            "recall_fake: 0.5566502463054187\n",
            "f1score_true: 0.6917960088691797\n",
            "f1score_fake: 0.6191780821917808\n",
            "Binary_loss 0.93905514\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.6892655367231638\n",
            "precision_fake: 0.6406926406926406\n",
            "recall_true: 0.5951219512195122\n",
            "recall_fake: 0.729064039408867\n",
            "f1score_true: 0.6387434554973821\n",
            "f1score_fake: 0.6820276497695852\n",
            "Binary_loss 0.86417085\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 27\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.6923076923076923\n",
            "precision_fake: 0.6504424778761062\n",
            "recall_true: 0.6146341463414634\n",
            "recall_fake: 0.7241379310344828\n",
            "f1score_true: 0.6511627906976745\n",
            "f1score_fake: 0.6853146853146854\n",
            "Binary_loss 0.9598545\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.6810810810810811\n",
            "precision_fake: 0.6457399103139013\n",
            "recall_true: 0.6146341463414634\n",
            "recall_fake: 0.7093596059113301\n",
            "f1score_true: 0.6461538461538462\n",
            "f1score_fake: 0.676056338028169\n",
            "Binary_loss 0.8719316\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 28\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.6422764227642277\n",
            "precision_fake: 0.7098765432098766\n",
            "recall_true: 0.7707317073170732\n",
            "recall_fake: 0.5665024630541872\n",
            "f1score_true: 0.7006651884700665\n",
            "f1score_fake: 0.6301369863013698\n",
            "Binary_loss 1.0712293\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.6735751295336787\n",
            "precision_fake: 0.6511627906976745\n",
            "recall_true: 0.6341463414634146\n",
            "recall_fake: 0.6896551724137931\n",
            "f1score_true: 0.6532663316582915\n",
            "f1score_fake: 0.6698564593301436\n",
            "Binary_loss 0.8915118\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 29\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.6428571428571429\n",
            "precision_fake: 0.7243589743589743\n",
            "recall_true: 0.7902439024390244\n",
            "recall_fake: 0.5566502463054187\n",
            "f1score_true: 0.7089715536105032\n",
            "f1score_fake: 0.6295264623955432\n",
            "Binary_loss 1.0371187\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.67\n",
            "precision_fake: 0.6586538461538461\n",
            "recall_true: 0.6536585365853659\n",
            "recall_fake: 0.6748768472906403\n",
            "f1score_true: 0.6617283950617284\n",
            "f1score_fake: 0.6666666666666666\n",
            "Binary_loss 0.91615206\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 30\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6568627450980392\n",
            "precision_true: 0.6737967914438503\n",
            "precision_fake: 0.6425339366515838\n",
            "recall_true: 0.6146341463414634\n",
            "recall_fake: 0.6995073891625616\n",
            "f1score_true: 0.6428571428571428\n",
            "f1score_fake: 0.6698113207547169\n",
            "Binary_loss 0.98763245\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6650485436893204\n",
            "precision_fake: 0.6633663366336634\n",
            "recall_true: 0.6682926829268293\n",
            "recall_fake: 0.6600985221674877\n",
            "f1score_true: 0.6666666666666667\n",
            "f1score_fake: 0.6617283950617284\n",
            "Binary_loss 0.9243405\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6537982565379825\n",
            "precision_true: 0.6824146981627297\n",
            "precision_fake: 0.6279620853080569\n",
            "recall_true: 0.6235011990407674\n",
            "recall_fake: 0.6865284974093264\n",
            "f1score_true: 0.6516290726817043\n",
            "f1score_fake: 0.6559405940594059\n",
            "Binary_loss 0.99827087\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6612702366127023\n",
            "precision_true: 0.6730310262529833\n",
            "precision_fake: 0.6484375\n",
            "recall_true: 0.6762589928057554\n",
            "recall_fake: 0.6450777202072538\n",
            "f1score_true: 0.6746411483253588\n",
            "f1score_fake: 0.6467532467532467\n",
            "Binary_loss 0.9109768\n",
            "-----------------------------------------------------------------\n",
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 831 799\n",
            "Test Label count : True, Fake 428 375\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 428ms/step - loss: 0.6937 - accuracy: 0.5016\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.4730392156862745\n",
            "precision_true: 0.75\n",
            "precision_fake: 0.4675\n",
            "recall_true: 0.0273972602739726\n",
            "recall_fake: 0.9894179894179894\n",
            "f1score_true: 0.05286343612334801\n",
            "f1score_fake: 0.634974533106961\n",
            "Binary_loss 0.69125366\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.69349146\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 2\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5147058823529411\n",
            "precision_true: 0.64\n",
            "precision_fake: 0.4864864864864865\n",
            "recall_true: 0.2191780821917808\n",
            "recall_fake: 0.8571428571428571\n",
            "f1score_true: 0.32653061224489793\n",
            "f1score_fake: 0.6206896551724138\n",
            "Binary_loss 0.6895393\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.693139\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 3\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5196078431372549\n",
            "precision_true: 0.6885245901639344\n",
            "precision_fake: 0.4899135446685879\n",
            "recall_true: 0.1917808219178082\n",
            "recall_fake: 0.8994708994708994\n",
            "f1score_true: 0.3\n",
            "f1score_fake: 0.6343283582089552\n",
            "Binary_loss 0.68871796\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.6930886\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 4\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5269607843137255\n",
            "precision_true: 0.7708333333333334\n",
            "precision_fake: 0.49444444444444446\n",
            "recall_true: 0.1689497716894977\n",
            "recall_fake: 0.9417989417989417\n",
            "f1score_true: 0.2771535580524344\n",
            "f1score_fake: 0.6484517304189434\n",
            "Binary_loss 0.68740577\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.6930867\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 5\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5563725490196079\n",
            "precision_true: 0.7065217391304348\n",
            "precision_fake: 0.5126582278481012\n",
            "recall_true: 0.2968036529680365\n",
            "recall_fake: 0.8571428571428571\n",
            "f1score_true: 0.4180064308681672\n",
            "f1score_fake: 0.6415841584158416\n",
            "Binary_loss 0.684455\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.6929585\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 6\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6029411764705882\n",
            "precision_true: 0.7355371900826446\n",
            "precision_fake: 0.5470383275261324\n",
            "recall_true: 0.4063926940639269\n",
            "recall_fake: 0.8306878306878307\n",
            "f1score_true: 0.5235294117647058\n",
            "f1score_fake: 0.6596638655462185\n",
            "Binary_loss 0.67704743\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.6925993\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 7\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5637254901960784\n",
            "precision_true: 0.8727272727272727\n",
            "precision_fake: 0.5155807365439093\n",
            "recall_true: 0.2191780821917808\n",
            "recall_fake: 0.9629629629629629\n",
            "f1score_true: 0.35036496350364965\n",
            "f1score_fake: 0.6715867158671587\n",
            "Binary_loss 0.66304153\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.6918235\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 8\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6470588235294118\n",
            "precision_true: 0.6153846153846154\n",
            "precision_fake: 0.7710843373493976\n",
            "recall_true: 0.91324200913242\n",
            "recall_fake: 0.3386243386243386\n",
            "f1score_true: 0.7352941176470589\n",
            "f1score_fake: 0.4705882352941176\n",
            "Binary_loss 0.6347044\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4632352941176471\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.4632352941176471\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6331658291457286\n",
            "Binary_loss 0.69051015\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 9\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.743801652892562\n",
            "precision_fake: 0.5505226480836237\n",
            "recall_true: 0.410958904109589\n",
            "recall_fake: 0.8359788359788359\n",
            "f1score_true: 0.5294117647058822\n",
            "f1score_fake: 0.6638655462184875\n",
            "Binary_loss 0.6343956\n",
            "*******TEACHER*************\n",
            "accuracy: 0.46568627450980393\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.4643734643734644\n",
            "recall_true: 0.0045662100456621\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.00909090909090909\n",
            "f1score_fake: 0.6342281879194631\n",
            "Binary_loss 0.68934464\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 10\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6299019607843137\n",
            "precision_true: 0.660377358490566\n",
            "precision_fake: 0.5969387755102041\n",
            "recall_true: 0.639269406392694\n",
            "recall_fake: 0.6190476190476191\n",
            "f1score_true: 0.6496519721577726\n",
            "f1score_fake: 0.6077922077922078\n",
            "Binary_loss 0.7110627\n",
            "*******TEACHER*************\n",
            "accuracy: 0.4803921568627451\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.4713216957605985\n",
            "recall_true: 0.0319634703196347\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.06194690265486725\n",
            "f1score_fake: 0.6406779661016949\n",
            "Binary_loss 0.6882161\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6164383561643836\n",
            "precision_true: 0.660427807486631\n",
            "precision_fake: 0.578088578088578\n",
            "recall_true: 0.5771028037383178\n",
            "recall_fake: 0.6613333333333333\n",
            "f1score_true: 0.6159600997506235\n",
            "f1score_fake: 0.6169154228855721\n",
            "Binary_loss 0.72198945\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.48941469489414696\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.47770700636942676\n",
            "recall_true: 0.04205607476635514\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.08071748878923767\n",
            "f1score_fake: 0.6465517241379309\n",
            "Binary_loss 0.6878196\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 11\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.6853448275862069\n",
            "precision_fake: 0.6590909090909091\n",
            "recall_true: 0.726027397260274\n",
            "recall_fake: 0.6137566137566137\n",
            "f1score_true: 0.70509977827051\n",
            "f1score_fake: 0.6356164383561644\n",
            "Binary_loss 0.6340163\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5024509803921569\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.48214285714285715\n",
            "recall_true: 0.0730593607305936\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.13617021276595745\n",
            "f1score_fake: 0.6506024096385542\n",
            "Binary_loss 0.6868822\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 12\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.6974358974358974\n",
            "precision_fake: 0.6103286384976526\n",
            "recall_true: 0.6210045662100456\n",
            "recall_fake: 0.6878306878306878\n",
            "f1score_true: 0.6570048309178744\n",
            "f1score_fake: 0.6467661691542289\n",
            "Binary_loss 0.65251094\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5294117647058824\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.49606299212598426\n",
            "recall_true: 0.1232876712328767\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.2195121951219512\n",
            "f1score_fake: 0.6631578947368421\n",
            "Binary_loss 0.6845758\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 13\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.696078431372549\n",
            "precision_true: 0.6970954356846473\n",
            "precision_fake: 0.6946107784431138\n",
            "recall_true: 0.7671232876712328\n",
            "recall_fake: 0.6137566137566137\n",
            "f1score_true: 0.7304347826086955\n",
            "f1score_fake: 0.651685393258427\n",
            "Binary_loss 0.6198962\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5514705882352942\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.5080645161290323\n",
            "recall_true: 0.1643835616438356\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.2823529411764706\n",
            "f1score_fake: 0.6737967914438503\n",
            "Binary_loss 0.68040663\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 14\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.7834394904458599\n",
            "precision_fake: 0.6175298804780877\n",
            "recall_true: 0.5616438356164384\n",
            "recall_fake: 0.8201058201058201\n",
            "f1score_true: 0.6542553191489362\n",
            "f1score_fake: 0.7045454545454546\n",
            "Binary_loss 0.6431972\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5686274509803921\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.5178082191780822\n",
            "recall_true: 0.1963470319634703\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.3282442748091603\n",
            "f1score_fake: 0.6823104693140795\n",
            "Binary_loss 0.6726756\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 15\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.8064516129032258\n",
            "precision_fake: 0.5809859154929577\n",
            "recall_true: 0.45662100456621\n",
            "recall_fake: 0.873015873015873\n",
            "f1score_true: 0.5830903790087463\n",
            "f1score_fake: 0.6976744186046512\n",
            "Binary_loss 0.626252\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5955882352941176\n",
            "precision_true: 0.9655172413793104\n",
            "precision_fake: 0.5342857142857143\n",
            "recall_true: 0.2557077625570776\n",
            "recall_fake: 0.9894179894179894\n",
            "f1score_true: 0.40433212996389883\n",
            "f1score_fake: 0.6938775510204082\n",
            "Binary_loss 0.6583578\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6625155666251556\n",
            "precision_true: 0.8127490039840638\n",
            "precision_fake: 0.5942028985507246\n",
            "recall_true: 0.4766355140186916\n",
            "recall_fake: 0.8746666666666667\n",
            "f1score_true: 0.6008836524300442\n",
            "f1score_fake: 0.7076591154261057\n",
            "Binary_loss 0.6438018\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.5740971357409713\n",
            "precision_true: 0.9387755102040817\n",
            "precision_fake: 0.5234042553191489\n",
            "recall_true: 0.21495327102803738\n",
            "recall_fake: 0.984\n",
            "f1score_true: 0.34980988593155893\n",
            "f1score_fake: 0.6833333333333333\n",
            "Binary_loss 0.65570575\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 16\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.8817204301075269\n",
            "precision_fake: 0.5650793650793651\n",
            "recall_true: 0.3744292237442922\n",
            "recall_fake: 0.9417989417989417\n",
            "f1score_true: 0.5256410256410255\n",
            "f1score_fake: 0.7063492063492064\n",
            "Binary_loss 0.72911817\n",
            "*******TEACHER*************\n",
            "accuracy: 0.625\n",
            "precision_true: 0.9125\n",
            "precision_fake: 0.5548780487804879\n",
            "recall_true: 0.3333333333333333\n",
            "recall_fake: 0.9629629629629629\n",
            "f1score_true: 0.48829431438127086\n",
            "f1score_fake: 0.7040618955512572\n",
            "Binary_loss 0.6327837\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 17\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.7696969696969697\n",
            "precision_fake: 0.6213991769547325\n",
            "recall_true: 0.5799086757990868\n",
            "recall_fake: 0.798941798941799\n",
            "f1score_true: 0.6614583333333333\n",
            "f1score_fake: 0.699074074074074\n",
            "Binary_loss 0.6468779\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6446078431372549\n",
            "precision_true: 0.8135593220338984\n",
            "precision_fake: 0.5758620689655173\n",
            "recall_true: 0.4383561643835616\n",
            "recall_fake: 0.8835978835978836\n",
            "f1score_true: 0.56973293768546\n",
            "f1score_fake: 0.697286012526096\n",
            "Binary_loss 0.5983325\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 18\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6838235294117647\n",
            "precision_true: 0.8\n",
            "precision_fake: 0.6162790697674418\n",
            "recall_true: 0.547945205479452\n",
            "recall_fake: 0.8412698412698413\n",
            "f1score_true: 0.6504065040650406\n",
            "f1score_fake: 0.7114093959731544\n",
            "Binary_loss 0.6636861\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.7529411764705882\n",
            "precision_fake: 0.6176470588235294\n",
            "recall_true: 0.5844748858447488\n",
            "recall_fake: 0.7777777777777778\n",
            "f1score_true: 0.6580976863753213\n",
            "f1score_fake: 0.6885245901639345\n",
            "Binary_loss 0.5693747\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 19\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6838235294117647\n",
            "precision_true: 0.6829268292682927\n",
            "precision_fake: 0.6851851851851852\n",
            "recall_true: 0.7671232876712328\n",
            "recall_fake: 0.5873015873015873\n",
            "f1score_true: 0.7225806451612903\n",
            "f1score_fake: 0.6324786324786325\n",
            "Binary_loss 0.66288465\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.7019230769230769\n",
            "precision_fake: 0.635\n",
            "recall_true: 0.6666666666666666\n",
            "recall_fake: 0.671957671957672\n",
            "f1score_true: 0.6838407494145198\n",
            "f1score_fake: 0.6529562982005143\n",
            "Binary_loss 0.5505015\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 20\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.717948717948718\n",
            "precision_fake: 0.6291079812206573\n",
            "recall_true: 0.639269406392694\n",
            "recall_fake: 0.708994708994709\n",
            "f1score_true: 0.6763285024154589\n",
            "f1score_fake: 0.6666666666666666\n",
            "Binary_loss 0.6201037\n",
            "*******TEACHER*************\n",
            "accuracy: 0.696078431372549\n",
            "precision_true: 0.6970954356846473\n",
            "precision_fake: 0.6946107784431138\n",
            "recall_true: 0.7671232876712328\n",
            "recall_fake: 0.6137566137566137\n",
            "f1score_true: 0.7304347826086955\n",
            "f1score_fake: 0.651685393258427\n",
            "Binary_loss 0.53952473\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6687422166874222\n",
            "precision_true: 0.7425149700598802\n",
            "precision_fake: 0.6162046908315565\n",
            "recall_true: 0.5794392523364486\n",
            "recall_fake: 0.7706666666666667\n",
            "f1score_true: 0.6509186351706037\n",
            "f1score_fake: 0.6848341232227488\n",
            "Binary_loss 0.6834794\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.684931506849315\n",
            "precision_true: 0.703962703962704\n",
            "precision_fake: 0.6631016042780749\n",
            "recall_true: 0.705607476635514\n",
            "recall_fake: 0.6613333333333333\n",
            "f1score_true: 0.7047841306884481\n",
            "f1score_fake: 0.6622162883845126\n",
            "Binary_loss 0.56551325\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 21\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.7619047619047619\n",
            "precision_fake: 0.6208333333333333\n",
            "recall_true: 0.5844748858447488\n",
            "recall_fake: 0.7883597883597884\n",
            "f1score_true: 0.661498708010336\n",
            "f1score_fake: 0.6946386946386947\n",
            "Binary_loss 0.68183243\n",
            "*******TEACHER*************\n",
            "accuracy: 0.696078431372549\n",
            "precision_true: 0.6833976833976834\n",
            "precision_fake: 0.7181208053691275\n",
            "recall_true: 0.8082191780821918\n",
            "recall_fake: 0.5661375661375662\n",
            "f1score_true: 0.7405857740585774\n",
            "f1score_fake: 0.6331360946745561\n",
            "Binary_loss 0.5406887\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 22\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6887254901960784\n",
            "precision_true: 0.6965811965811965\n",
            "precision_fake: 0.6781609195402298\n",
            "recall_true: 0.7442922374429224\n",
            "recall_fake: 0.6243386243386243\n",
            "f1score_true: 0.7196467991169977\n",
            "f1score_fake: 0.650137741046832\n",
            "Binary_loss 0.6618477\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6887254901960784\n",
            "precision_true: 0.6796875\n",
            "precision_fake: 0.7039473684210527\n",
            "recall_true: 0.7945205479452054\n",
            "recall_fake: 0.5661375661375662\n",
            "f1score_true: 0.7326315789473683\n",
            "f1score_fake: 0.6275659824046922\n",
            "Binary_loss 0.5531682\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 23\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.6968325791855203\n",
            "precision_fake: 0.6524064171122995\n",
            "recall_true: 0.7031963470319634\n",
            "recall_fake: 0.6455026455026455\n",
            "f1score_true: 0.6999999999999998\n",
            "f1score_fake: 0.648936170212766\n",
            "Binary_loss 0.68978673\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6862745098039216\n",
            "precision_true: 0.6812749003984063\n",
            "precision_fake: 0.6942675159235668\n",
            "recall_true: 0.7808219178082192\n",
            "recall_fake: 0.5767195767195767\n",
            "f1score_true: 0.7276595744680852\n",
            "f1score_fake: 0.630057803468208\n",
            "Binary_loss 0.55973345\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 24\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6666666666666666\n",
            "precision_true: 0.7610062893081762\n",
            "precision_fake: 0.606425702811245\n",
            "recall_true: 0.5525114155251142\n",
            "recall_fake: 0.798941798941799\n",
            "f1score_true: 0.6402116402116402\n",
            "f1score_fake: 0.6894977168949771\n",
            "Binary_loss 0.7505278\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6887254901960784\n",
            "precision_true: 0.6811023622047244\n",
            "precision_fake: 0.7012987012987013\n",
            "recall_true: 0.7899543378995434\n",
            "recall_fake: 0.5714285714285714\n",
            "f1score_true: 0.7315010570824525\n",
            "f1score_fake: 0.6297376093294461\n",
            "Binary_loss 0.57238007\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 25\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6862745098039216\n",
            "precision_true: 0.7357512953367875\n",
            "precision_fake: 0.641860465116279\n",
            "recall_true: 0.6484018264840182\n",
            "recall_fake: 0.7301587301587301\n",
            "f1score_true: 0.6893203883495145\n",
            "f1score_fake: 0.6831683168316831\n",
            "Binary_loss 0.75229526\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6887254901960784\n",
            "precision_true: 0.6900826446280992\n",
            "precision_fake: 0.6867469879518072\n",
            "recall_true: 0.7625570776255708\n",
            "recall_fake: 0.6031746031746031\n",
            "f1score_true: 0.7245119305856834\n",
            "f1score_fake: 0.6422535211267606\n",
            "Binary_loss 0.58717066\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6712328767123288\n",
            "precision_true: 0.7469879518072289\n",
            "precision_fake: 0.6178343949044586\n",
            "recall_true: 0.5794392523364486\n",
            "recall_fake: 0.776\n",
            "f1score_true: 0.6526315789473685\n",
            "f1score_fake: 0.6879432624113476\n",
            "Binary_loss 0.87318116\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6824408468244084\n",
            "precision_true: 0.6952595936794582\n",
            "precision_fake: 0.6666666666666666\n",
            "recall_true: 0.719626168224299\n",
            "recall_fake: 0.64\n",
            "f1score_true: 0.7072330654420206\n",
            "f1score_fake: 0.6530612244897959\n",
            "Binary_loss 0.6367594\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 26\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.6679245283018868\n",
            "precision_fake: 0.7062937062937062\n",
            "recall_true: 0.8082191780821918\n",
            "recall_fake: 0.5343915343915344\n",
            "f1score_true: 0.731404958677686\n",
            "f1score_fake: 0.608433734939759\n",
            "Binary_loss 0.8229239\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6838235294117647\n",
            "precision_true: 0.6875\n",
            "precision_fake: 0.6785714285714286\n",
            "recall_true: 0.7534246575342466\n",
            "recall_fake: 0.6031746031746031\n",
            "f1score_true: 0.7189542483660132\n",
            "f1score_fake: 0.638655462184874\n",
            "Binary_loss 0.60089064\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 27\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.6745098039215687\n",
            "precision_fake: 0.6928104575163399\n",
            "recall_true: 0.7853881278538812\n",
            "recall_fake: 0.5608465608465608\n",
            "f1score_true: 0.7257383966244725\n",
            "f1score_fake: 0.6198830409356726\n",
            "Binary_loss 0.8332988\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.6763485477178424\n",
            "precision_fake: 0.6646706586826348\n",
            "recall_true: 0.7442922374429224\n",
            "recall_fake: 0.5873015873015873\n",
            "f1score_true: 0.7086956521739131\n",
            "f1score_fake: 0.6235955056179775\n",
            "Binary_loss 0.61897516\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 28\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6666666666666666\n",
            "precision_true: 0.6860986547085202\n",
            "precision_fake: 0.6432432432432432\n",
            "recall_true: 0.6986301369863014\n",
            "recall_fake: 0.6296296296296297\n",
            "f1score_true: 0.6923076923076923\n",
            "f1score_fake: 0.6363636363636364\n",
            "Binary_loss 0.8161521\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.6866952789699571\n",
            "precision_fake: 0.6628571428571428\n",
            "recall_true: 0.730593607305936\n",
            "recall_fake: 0.6137566137566137\n",
            "f1score_true: 0.7079646017699114\n",
            "f1score_fake: 0.6373626373626373\n",
            "Binary_loss 0.6379055\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 29\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6544117647058824\n",
            "precision_true: 0.825\n",
            "precision_fake: 0.5833333333333334\n",
            "recall_true: 0.4520547945205479\n",
            "recall_fake: 0.8888888888888888\n",
            "f1score_true: 0.584070796460177\n",
            "f1score_fake: 0.7044025157232704\n",
            "Binary_loss 0.857293\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.6866952789699571\n",
            "precision_fake: 0.6628571428571428\n",
            "recall_true: 0.730593607305936\n",
            "recall_fake: 0.6137566137566137\n",
            "f1score_true: 0.7079646017699114\n",
            "f1score_fake: 0.6373626373626373\n",
            "Binary_loss 0.6601365\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 30\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6568627450980392\n",
            "precision_true: 0.7309941520467836\n",
            "precision_fake: 0.6033755274261603\n",
            "recall_true: 0.5707762557077626\n",
            "recall_fake: 0.7566137566137566\n",
            "f1score_true: 0.6410256410256411\n",
            "f1score_fake: 0.6713615023474178\n",
            "Binary_loss 0.72954196\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6830357142857143\n",
            "precision_fake: 0.6413043478260869\n",
            "recall_true: 0.6986301369863014\n",
            "recall_fake: 0.6243386243386243\n",
            "f1score_true: 0.690744920993228\n",
            "f1score_fake: 0.6327077747989276\n",
            "Binary_loss 0.6713894\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6425902864259029\n",
            "precision_true: 0.7508896797153025\n",
            "precision_fake: 0.5842911877394636\n",
            "recall_true: 0.4929906542056075\n",
            "recall_fake: 0.8133333333333334\n",
            "f1score_true: 0.5952045133991538\n",
            "f1score_fake: 0.6800445930880714\n",
            "Binary_loss 0.82283354\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6687422166874222\n",
            "precision_true: 0.7014925373134329\n",
            "precision_fake: 0.6359102244389028\n",
            "recall_true: 0.6588785046728972\n",
            "recall_fake: 0.68\n",
            "f1score_true: 0.6795180722891565\n",
            "f1score_fake: 0.6572164948453609\n",
            "Binary_loss 0.7508127\n",
            "-----------------------------------------------------------------\n",
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 842 788\n",
            "Test Label count : True, Fake 417 386\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 433ms/step - loss: 0.6921 - accuracy: 0.5352\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.46568627450980393\n",
            "precision_true: 0.4697508896797153\n",
            "precision_fake: 0.4566929133858268\n",
            "recall_true: 0.6567164179104478\n",
            "recall_fake: 0.28019323671497587\n",
            "f1score_true: 0.5477178423236515\n",
            "f1score_fake: 0.34730538922155696\n",
            "Binary_loss 0.69526535\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5073529411764706\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5073529411764706\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.673170731707317\n",
            "Binary_loss 0.69353664\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 2\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.4877450980392157\n",
            "precision_true: 0.4862068965517241\n",
            "precision_fake: 0.4915254237288136\n",
            "recall_true: 0.7014925373134329\n",
            "recall_fake: 0.28019323671497587\n",
            "f1score_true: 0.5743380855397149\n",
            "f1score_fake: 0.35692307692307695\n",
            "Binary_loss 0.69742566\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5073529411764706\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5073529411764706\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.673170731707317\n",
            "Binary_loss 0.69326705\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 3\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.48284313725490197\n",
            "precision_true: 0.4825174825174825\n",
            "precision_fake: 0.48360655737704916\n",
            "recall_true: 0.6865671641791045\n",
            "recall_fake: 0.28502415458937197\n",
            "f1score_true: 0.5667351129363449\n",
            "f1score_fake: 0.35866261398176297\n",
            "Binary_loss 0.6970508\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5073529411764706\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5073529411764706\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.673170731707317\n",
            "Binary_loss 0.69313353\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 4\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.4803921568627451\n",
            "precision_true: 0.4807017543859649\n",
            "precision_fake: 0.4796747967479675\n",
            "recall_true: 0.681592039800995\n",
            "recall_fake: 0.28502415458937197\n",
            "f1score_true: 0.5637860082304527\n",
            "f1score_fake: 0.3575757575757576\n",
            "Binary_loss 0.69688326\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5073529411764706\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5073529411764706\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.673170731707317\n",
            "Binary_loss 0.6930537\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 5\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.4803921568627451\n",
            "precision_true: 0.4807017543859649\n",
            "precision_fake: 0.4796747967479675\n",
            "recall_true: 0.681592039800995\n",
            "recall_fake: 0.28502415458937197\n",
            "f1score_true: 0.5637860082304527\n",
            "f1score_fake: 0.3575757575757576\n",
            "Binary_loss 0.6944807\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5073529411764706\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5073529411764706\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.673170731707317\n",
            "Binary_loss 0.6929619\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 6\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.4877450980392157\n",
            "precision_true: 0.4862068965517241\n",
            "precision_fake: 0.4915254237288136\n",
            "recall_true: 0.7014925373134329\n",
            "recall_fake: 0.28019323671497587\n",
            "f1score_true: 0.5743380855397149\n",
            "f1score_fake: 0.35692307692307695\n",
            "Binary_loss 0.6919075\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5073529411764706\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5073529411764706\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.673170731707317\n",
            "Binary_loss 0.6928297\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 7\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5220588235294118\n",
            "precision_true: 0.5099337748344371\n",
            "precision_fake: 0.5566037735849056\n",
            "recall_true: 0.7661691542288557\n",
            "recall_fake: 0.28502415458937197\n",
            "f1score_true: 0.6123260437375746\n",
            "f1score_fake: 0.37699680511182104\n",
            "Binary_loss 0.6992243\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5612745098039216\n",
            "precision_true: 0.625\n",
            "precision_fake: 0.54375\n",
            "recall_true: 0.2736318407960199\n",
            "recall_fake: 0.8405797101449275\n",
            "f1score_true: 0.3806228373702422\n",
            "f1score_fake: 0.6603415559772295\n",
            "Binary_loss 0.6924911\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 8\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5563725490196079\n",
            "precision_true: 0.7380952380952381\n",
            "precision_fake: 0.5355191256830601\n",
            "recall_true: 0.15422885572139303\n",
            "recall_fake: 0.9468599033816425\n",
            "f1score_true: 0.2551440329218107\n",
            "f1score_fake: 0.6841186736474696\n",
            "Binary_loss 0.66462326\n",
            "*******TEACHER*************\n",
            "accuracy: 0.49754901960784315\n",
            "precision_true: 0.4911504424778761\n",
            "precision_fake: 0.5054945054945055\n",
            "recall_true: 0.5522388059701493\n",
            "recall_fake: 0.4444444444444444\n",
            "f1score_true: 0.5199063231850117\n",
            "f1score_fake: 0.47300771208226217\n",
            "Binary_loss 0.69183433\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 9\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5857843137254902\n",
            "precision_true: 0.6176470588235294\n",
            "precision_fake: 0.5698529411764706\n",
            "recall_true: 0.417910447761194\n",
            "recall_fake: 0.748792270531401\n",
            "f1score_true: 0.49851632047477745\n",
            "f1score_fake: 0.6471816283924843\n",
            "Binary_loss 0.77170306\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5098039215686274\n",
            "precision_true: 0.502092050209205\n",
            "precision_fake: 0.5207100591715976\n",
            "recall_true: 0.5970149253731343\n",
            "recall_fake: 0.4251207729468599\n",
            "f1score_true: 0.5454545454545454\n",
            "f1score_fake: 0.46808510638297873\n",
            "Binary_loss 0.6903112\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 10\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6323529411764706\n",
            "precision_true: 0.7256637168141593\n",
            "precision_fake: 0.5966101694915255\n",
            "recall_true: 0.4079601990049751\n",
            "recall_fake: 0.8502415458937198\n",
            "f1score_true: 0.5222929936305732\n",
            "f1score_fake: 0.701195219123506\n",
            "Binary_loss 0.6890596\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5367647058823529\n",
            "precision_true: 0.5256410256410257\n",
            "precision_fake: 0.5517241379310345\n",
            "recall_true: 0.6119402985074627\n",
            "recall_fake: 0.463768115942029\n",
            "f1score_true: 0.5655172413793103\n",
            "f1score_fake: 0.5039370078740157\n",
            "Binary_loss 0.6876378\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.638854296388543\n",
            "precision_true: 0.8190954773869347\n",
            "precision_fake: 0.5794701986754967\n",
            "recall_true: 0.3908872901678657\n",
            "recall_fake: 0.9067357512953368\n",
            "f1score_true: 0.5292207792207793\n",
            "f1score_fake: 0.707070707070707\n",
            "Binary_loss 0.65394336\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.5990037359900373\n",
            "precision_true: 0.5948103792415169\n",
            "precision_fake: 0.6059602649006622\n",
            "recall_true: 0.7146282973621103\n",
            "recall_fake: 0.4740932642487047\n",
            "f1score_true: 0.6492374727668845\n",
            "f1score_fake: 0.5319767441860465\n",
            "Binary_loss 0.68310744\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 11\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6348039215686274\n",
            "precision_true: 0.6444444444444445\n",
            "precision_fake: 0.6271929824561403\n",
            "recall_true: 0.5771144278606966\n",
            "recall_fake: 0.6908212560386473\n",
            "f1score_true: 0.6089238845144358\n",
            "f1score_fake: 0.657471264367816\n",
            "Binary_loss 0.7471197\n",
            "*******TEACHER*************\n",
            "accuracy: 0.571078431372549\n",
            "precision_true: 0.5511811023622047\n",
            "precision_fake: 0.6038961038961039\n",
            "recall_true: 0.6965174129353234\n",
            "recall_fake: 0.4492753623188406\n",
            "f1score_true: 0.6153846153846154\n",
            "f1score_fake: 0.515235457063712\n",
            "Binary_loss 0.6836401\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 12\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6299019607843137\n",
            "precision_true: 0.6059322033898306\n",
            "precision_fake: 0.6627906976744186\n",
            "recall_true: 0.7114427860696517\n",
            "recall_fake: 0.5507246376811594\n",
            "f1score_true: 0.6544622425629291\n",
            "f1score_fake: 0.6015831134564643\n",
            "Binary_loss 0.7889006\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5931372549019608\n",
            "precision_true: 0.5636363636363636\n",
            "precision_fake: 0.6541353383458647\n",
            "recall_true: 0.7711442786069652\n",
            "recall_fake: 0.42028985507246375\n",
            "f1score_true: 0.6512605042016807\n",
            "f1score_fake: 0.5117647058823529\n",
            "Binary_loss 0.67830795\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 13\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6348039215686274\n",
            "precision_true: 0.63\n",
            "precision_fake: 0.6394230769230769\n",
            "recall_true: 0.6268656716417911\n",
            "recall_fake: 0.642512077294686\n",
            "f1score_true: 0.6284289276807982\n",
            "f1score_fake: 0.6409638554216867\n",
            "Binary_loss 0.81593996\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5882352941176471\n",
            "precision_true: 0.5574912891986062\n",
            "precision_fake: 0.6611570247933884\n",
            "recall_true: 0.7960199004975125\n",
            "recall_fake: 0.3864734299516908\n",
            "f1score_true: 0.6557377049180327\n",
            "f1score_fake: 0.48780487804878053\n",
            "Binary_loss 0.67184895\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 14\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6446078431372549\n",
            "precision_true: 0.609375\n",
            "precision_fake: 0.7039473684210527\n",
            "recall_true: 0.7761194029850746\n",
            "recall_fake: 0.5169082125603864\n",
            "f1score_true: 0.6827133479212254\n",
            "f1score_fake: 0.5961002785515319\n",
            "Binary_loss 0.7184615\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5882352941176471\n",
            "precision_true: 0.5574912891986062\n",
            "precision_fake: 0.6611570247933884\n",
            "recall_true: 0.7960199004975125\n",
            "recall_fake: 0.3864734299516908\n",
            "f1score_true: 0.6557377049180327\n",
            "f1score_fake: 0.48780487804878053\n",
            "Binary_loss 0.6636968\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 15\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.676923076923077\n",
            "precision_fake: 0.5935251798561151\n",
            "recall_true: 0.43781094527363185\n",
            "recall_fake: 0.7971014492753623\n",
            "f1score_true: 0.5317220543806647\n",
            "f1score_fake: 0.6804123711340206\n",
            "Binary_loss 0.8851785\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5833333333333334\n",
            "precision_true: 0.5532646048109966\n",
            "precision_fake: 0.6581196581196581\n",
            "recall_true: 0.8009950248756219\n",
            "recall_fake: 0.3719806763285024\n",
            "f1score_true: 0.6544715447154472\n",
            "f1score_fake: 0.47530864197530864\n",
            "Binary_loss 0.65790033\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6450809464508095\n",
            "precision_true: 0.7661290322580645\n",
            "precision_fake: 0.590990990990991\n",
            "recall_true: 0.4556354916067146\n",
            "recall_fake: 0.8497409326424871\n",
            "f1score_true: 0.5714285714285714\n",
            "f1score_fake: 0.6971307120085015\n",
            "Binary_loss 0.7541016\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6650062266500623\n",
            "precision_true: 0.6262798634812287\n",
            "precision_fake: 0.7695852534562212\n",
            "recall_true: 0.8800959232613909\n",
            "recall_fake: 0.4326424870466321\n",
            "f1score_true: 0.7318045862412762\n",
            "f1score_fake: 0.5538971807628523\n",
            "Binary_loss 0.6289461\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 16\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6225490196078431\n",
            "precision_true: 0.6821705426356589\n",
            "precision_fake: 0.5949820788530465\n",
            "recall_true: 0.43781094527363185\n",
            "recall_fake: 0.8019323671497585\n",
            "f1score_true: 0.5333333333333333\n",
            "f1score_fake: 0.6831275720164608\n",
            "Binary_loss 0.9005861\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5882352941176471\n",
            "precision_true: 0.5578947368421052\n",
            "precision_fake: 0.6585365853658537\n",
            "recall_true: 0.7910447761194029\n",
            "recall_fake: 0.391304347826087\n",
            "f1score_true: 0.654320987654321\n",
            "f1score_fake: 0.49090909090909096\n",
            "Binary_loss 0.64815295\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 17\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6323529411764706\n",
            "precision_true: 0.6457142857142857\n",
            "precision_fake: 0.6223175965665236\n",
            "recall_true: 0.5621890547263682\n",
            "recall_fake: 0.7004830917874396\n",
            "f1score_true: 0.601063829787234\n",
            "f1score_fake: 0.6590909090909092\n",
            "Binary_loss 0.811529\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5980392156862745\n",
            "precision_true: 0.5677655677655677\n",
            "precision_fake: 0.6592592592592592\n",
            "recall_true: 0.7711442786069652\n",
            "recall_fake: 0.42995169082125606\n",
            "f1score_true: 0.6540084388185653\n",
            "f1score_fake: 0.52046783625731\n",
            "Binary_loss 0.64111805\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 18\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6225490196078431\n",
            "precision_true: 0.6217616580310881\n",
            "precision_fake: 0.6232558139534884\n",
            "recall_true: 0.5970149253731343\n",
            "recall_fake: 0.6473429951690821\n",
            "f1score_true: 0.6091370558375634\n",
            "f1score_fake: 0.6350710900473935\n",
            "Binary_loss 0.96462756\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6151960784313726\n",
            "precision_true: 0.5846153846153846\n",
            "precision_fake: 0.668918918918919\n",
            "recall_true: 0.7562189054726368\n",
            "recall_fake: 0.4782608695652174\n",
            "f1score_true: 0.6594360086767896\n",
            "f1score_fake: 0.5577464788732395\n",
            "Binary_loss 0.6417787\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 19\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.6716417910447762\n",
            "precision_fake: 0.5948905109489051\n",
            "recall_true: 0.44776119402985076\n",
            "recall_fake: 0.7874396135265701\n",
            "f1score_true: 0.5373134328358209\n",
            "f1score_fake: 0.6777546777546777\n",
            "Binary_loss 1.0834122\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.606425702811245\n",
            "precision_fake: 0.6855345911949685\n",
            "recall_true: 0.7512437810945274\n",
            "recall_fake: 0.5265700483091788\n",
            "f1score_true: 0.6711111111111111\n",
            "f1score_fake: 0.5956284153005464\n",
            "Binary_loss 0.65954155\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 20\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.6236559139784946\n",
            "precision_fake: 0.6171171171171171\n",
            "recall_true: 0.5771144278606966\n",
            "recall_fake: 0.6618357487922706\n",
            "f1score_true: 0.599483204134367\n",
            "f1score_fake: 0.6386946386946388\n",
            "Binary_loss 0.97989327\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.6137339055793991\n",
            "precision_fake: 0.6685714285714286\n",
            "recall_true: 0.7114427860696517\n",
            "recall_fake: 0.5652173913043478\n",
            "f1score_true: 0.6589861751152073\n",
            "f1score_fake: 0.612565445026178\n",
            "Binary_loss 0.6887401\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.651307596513076\n",
            "precision_true: 0.6876712328767123\n",
            "precision_fake: 0.6210045662100456\n",
            "recall_true: 0.6019184652278178\n",
            "recall_fake: 0.7046632124352331\n",
            "f1score_true: 0.6419437340153452\n",
            "f1score_fake: 0.6601941747572816\n",
            "Binary_loss 0.8100926\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6824408468244084\n",
            "precision_true: 0.6673553719008265\n",
            "precision_fake: 0.7053291536050157\n",
            "recall_true: 0.7745803357314148\n",
            "recall_fake: 0.582901554404145\n",
            "f1score_true: 0.7169811320754718\n",
            "f1score_fake: 0.6382978723404256\n",
            "Binary_loss 0.5838377\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 21\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6299019607843137\n",
            "precision_true: 0.6373626373626373\n",
            "precision_fake: 0.6238938053097345\n",
            "recall_true: 0.5771144278606966\n",
            "recall_fake: 0.6811594202898551\n",
            "f1score_true: 0.6057441253263708\n",
            "f1score_fake: 0.6512702078521939\n",
            "Binary_loss 1.007049\n",
            "*******TEACHER*************\n",
            "accuracy: 0.625\n",
            "precision_true: 0.6100917431192661\n",
            "precision_fake: 0.6421052631578947\n",
            "recall_true: 0.6616915422885572\n",
            "recall_fake: 0.5893719806763285\n",
            "f1score_true: 0.6348448687350835\n",
            "f1score_fake: 0.6146095717884131\n",
            "Binary_loss 0.72036064\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 22\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6176470588235294\n",
            "precision_true: 0.6142131979695431\n",
            "precision_fake: 0.6208530805687204\n",
            "recall_true: 0.6019900497512438\n",
            "recall_fake: 0.6328502415458938\n",
            "f1score_true: 0.6080402010050251\n",
            "f1score_fake: 0.6267942583732057\n",
            "Binary_loss 0.9817966\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6225490196078431\n",
            "precision_true: 0.6093023255813953\n",
            "precision_fake: 0.6373056994818653\n",
            "recall_true: 0.6517412935323383\n",
            "recall_fake: 0.5942028985507246\n",
            "f1score_true: 0.6298076923076924\n",
            "f1score_fake: 0.615\n",
            "Binary_loss 0.7599871\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 23\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6225490196078431\n",
            "precision_true: 0.6459627329192547\n",
            "precision_fake: 0.6072874493927125\n",
            "recall_true: 0.5174129353233831\n",
            "recall_fake: 0.7246376811594203\n",
            "f1score_true: 0.574585635359116\n",
            "f1score_fake: 0.6607929515418502\n",
            "Binary_loss 0.99677366\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.6095238095238096\n",
            "precision_fake: 0.6313131313131313\n",
            "recall_true: 0.6368159203980099\n",
            "recall_fake: 0.6038647342995169\n",
            "f1score_true: 0.6228710462287105\n",
            "f1score_fake: 0.6172839506172839\n",
            "Binary_loss 0.79474354\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 24\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6323529411764706\n",
            "precision_true: 0.6197183098591549\n",
            "precision_fake: 0.6461538461538462\n",
            "recall_true: 0.6567164179104478\n",
            "recall_fake: 0.6086956521739131\n",
            "f1score_true: 0.6376811594202898\n",
            "f1score_fake: 0.6268656716417911\n",
            "Binary_loss 1.0060303\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.6116504854368932\n",
            "precision_fake: 0.6287128712871287\n",
            "recall_true: 0.6268656716417911\n",
            "recall_fake: 0.6135265700483091\n",
            "f1score_true: 0.6191646191646192\n",
            "f1score_fake: 0.6210268948655256\n",
            "Binary_loss 0.82348067\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 25\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.6645962732919255\n",
            "precision_fake: 0.6194331983805668\n",
            "recall_true: 0.5323383084577115\n",
            "recall_fake: 0.7391304347826086\n",
            "f1score_true: 0.5911602209944751\n",
            "f1score_fake: 0.6740088105726872\n",
            "Binary_loss 1.1568468\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.6116504854368932\n",
            "precision_fake: 0.6287128712871287\n",
            "recall_true: 0.6268656716417911\n",
            "recall_fake: 0.6135265700483091\n",
            "f1score_true: 0.6191646191646192\n",
            "f1score_fake: 0.6210268948655256\n",
            "Binary_loss 0.8665384\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.638854296388543\n",
            "precision_true: 0.6990595611285266\n",
            "precision_fake: 0.5991735537190083\n",
            "recall_true: 0.5347721822541966\n",
            "recall_fake: 0.7512953367875648\n",
            "f1score_true: 0.6059782608695652\n",
            "f1score_fake: 0.6666666666666666\n",
            "Binary_loss 1.0538782\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.651307596513076\n",
            "precision_true: 0.6658595641646489\n",
            "precision_fake: 0.6358974358974359\n",
            "recall_true: 0.6594724220623501\n",
            "recall_fake: 0.6424870466321243\n",
            "f1score_true: 0.6626506024096385\n",
            "f1score_fake: 0.6391752577319586\n",
            "Binary_loss 0.7022078\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 26\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.625\n",
            "precision_true: 0.6290322580645161\n",
            "precision_fake: 0.6216216216216216\n",
            "recall_true: 0.582089552238806\n",
            "recall_fake: 0.6666666666666666\n",
            "f1score_true: 0.6046511627906976\n",
            "f1score_fake: 0.6433566433566433\n",
            "Binary_loss 0.9743637\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6200980392156863\n",
            "precision_true: 0.6116504854368932\n",
            "precision_fake: 0.6287128712871287\n",
            "recall_true: 0.6268656716417911\n",
            "recall_fake: 0.6135265700483091\n",
            "f1score_true: 0.6191646191646192\n",
            "f1score_fake: 0.6210268948655256\n",
            "Binary_loss 0.88757086\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 27\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6348039215686274\n",
            "precision_true: 0.6274509803921569\n",
            "precision_fake: 0.6421568627450981\n",
            "recall_true: 0.6368159203980099\n",
            "recall_fake: 0.6328502415458938\n",
            "f1score_true: 0.6320987654320988\n",
            "f1score_fake: 0.6374695863746959\n",
            "Binary_loss 1.044444\n",
            "*******TEACHER*************\n",
            "accuracy: 0.625\n",
            "precision_true: 0.616504854368932\n",
            "precision_fake: 0.6336633663366337\n",
            "recall_true: 0.6318407960199005\n",
            "recall_fake: 0.6183574879227053\n",
            "f1score_true: 0.624078624078624\n",
            "f1score_fake: 0.6259168704156479\n",
            "Binary_loss 0.90114266\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 28\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6397058823529411\n",
            "precision_true: 0.6227272727272727\n",
            "precision_fake: 0.6595744680851063\n",
            "recall_true: 0.681592039800995\n",
            "recall_fake: 0.5990338164251208\n",
            "f1score_true: 0.6508313539192399\n",
            "f1score_fake: 0.6278481012658227\n",
            "Binary_loss 1.1621553\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6176470588235294\n",
            "precision_true: 0.6119402985074627\n",
            "precision_fake: 0.6231884057971014\n",
            "recall_true: 0.6119402985074627\n",
            "recall_fake: 0.6231884057971014\n",
            "f1score_true: 0.6119402985074627\n",
            "f1score_fake: 0.6231884057971014\n",
            "Binary_loss 0.9375615\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 29\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6151960784313726\n",
            "precision_true: 0.6264367816091954\n",
            "precision_fake: 0.6068376068376068\n",
            "recall_true: 0.5422885572139303\n",
            "recall_fake: 0.6859903381642513\n",
            "f1score_true: 0.5813333333333333\n",
            "f1score_fake: 0.6439909297052154\n",
            "Binary_loss 1.090878\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6102941176470589\n",
            "precision_true: 0.609375\n",
            "precision_fake: 0.6111111111111112\n",
            "recall_true: 0.582089552238806\n",
            "recall_fake: 0.6376811594202898\n",
            "f1score_true: 0.5954198473282443\n",
            "f1score_fake: 0.624113475177305\n",
            "Binary_loss 0.9576014\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 30\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6299019607843137\n",
            "precision_true: 0.631578947368421\n",
            "precision_fake: 0.6284403669724771\n",
            "recall_true: 0.5970149253731343\n",
            "recall_fake: 0.6618357487922706\n",
            "f1score_true: 0.6138107416879794\n",
            "f1score_fake: 0.6447058823529412\n",
            "Binary_loss 1.1443087\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6102941176470589\n",
            "precision_true: 0.6082474226804123\n",
            "precision_fake: 0.6121495327102804\n",
            "recall_true: 0.5870646766169154\n",
            "recall_fake: 0.6328502415458938\n",
            "f1score_true: 0.5974683544303798\n",
            "f1score_fake: 0.6223277909738717\n",
            "Binary_loss 0.9813817\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6450809464508095\n",
            "precision_true: 0.6853932584269663\n",
            "precision_fake: 0.6129753914988815\n",
            "recall_true: 0.5851318944844125\n",
            "recall_fake: 0.7098445595854922\n",
            "f1score_true: 0.6313065976714102\n",
            "f1score_fake: 0.6578631452581033\n",
            "Binary_loss 1.033668\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6575342465753424\n",
            "precision_true: 0.6878306878306878\n",
            "precision_fake: 0.6305882352941177\n",
            "recall_true: 0.6235011990407674\n",
            "recall_fake: 0.694300518134715\n",
            "f1score_true: 0.6540880503144654\n",
            "f1score_fake: 0.6609124537607892\n",
            "Binary_loss 0.84048116\n",
            "-----------------------------------------------------------------\n",
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 836 794\n",
            "Test Label count : True, Fake 423 380\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 428ms/step - loss: 0.6925 - accuracy: 0.5123\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5367647058823529\n",
            "precision_true: 0.5142857142857142\n",
            "precision_fake: 0.5859375\n",
            "recall_true: 0.7309644670050761\n",
            "recall_fake: 0.35545023696682465\n",
            "f1score_true: 0.6037735849056604\n",
            "f1score_fake: 0.44247787610619466\n",
            "Binary_loss 0.6926563\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5245098039215687\n",
            "precision_true: 0.6666666666666666\n",
            "precision_fake: 0.5213032581453634\n",
            "recall_true: 0.030456852791878174\n",
            "recall_fake: 0.985781990521327\n",
            "f1score_true: 0.05825242718446602\n",
            "f1score_fake: 0.6819672131147541\n",
            "Binary_loss 0.69287467\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 2\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5392156862745098\n",
            "precision_true: 0.5157894736842106\n",
            "precision_fake: 0.5934959349593496\n",
            "recall_true: 0.7461928934010152\n",
            "recall_fake: 0.3459715639810427\n",
            "f1score_true: 0.6099585062240663\n",
            "f1score_fake: 0.437125748502994\n",
            "Binary_loss 0.6920305\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5171568627450981\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5171568627450981\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6817447495961229\n",
            "Binary_loss 0.69300187\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 3\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5612745098039216\n",
            "precision_true: 0.5304054054054054\n",
            "precision_fake: 0.6428571428571429\n",
            "recall_true: 0.7969543147208121\n",
            "recall_fake: 0.3412322274881517\n",
            "f1score_true: 0.6369168356997972\n",
            "f1score_fake: 0.4458204334365325\n",
            "Binary_loss 0.6914115\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5171568627450981\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5171568627450981\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6817447495961229\n",
            "Binary_loss 0.69302446\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 4\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5833333333333334\n",
            "precision_true: 0.5431309904153354\n",
            "precision_fake: 0.7157894736842105\n",
            "recall_true: 0.8629441624365483\n",
            "recall_fake: 0.3222748815165877\n",
            "f1score_true: 0.6666666666666667\n",
            "f1score_fake: 0.4444444444444445\n",
            "Binary_loss 0.6904433\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5171568627450981\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5171568627450981\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6817447495961229\n",
            "Binary_loss 0.6929498\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 5\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.557632398753894\n",
            "precision_fake: 0.7931034482758621\n",
            "recall_true: 0.9086294416243654\n",
            "recall_fake: 0.32701421800947866\n",
            "f1score_true: 0.691119691119691\n",
            "f1score_fake: 0.4630872483221477\n",
            "Binary_loss 0.6882674\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5171568627450981\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5171568627450981\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6817447495961229\n",
            "Binary_loss 0.6927557\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 6\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6102941176470589\n",
            "precision_true: 0.5608974358974359\n",
            "precision_fake: 0.7708333333333334\n",
            "recall_true: 0.8883248730964467\n",
            "recall_fake: 0.35071090047393366\n",
            "f1score_true: 0.6876227897838899\n",
            "f1score_fake: 0.482084690553746\n",
            "Binary_loss 0.683369\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5171568627450981\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.5171568627450981\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6817447495961229\n",
            "Binary_loss 0.6923829\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 7\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6029411764705882\n",
            "precision_true: 0.7160493827160493\n",
            "precision_fake: 0.5749235474006116\n",
            "recall_true: 0.29441624365482233\n",
            "recall_fake: 0.8909952606635071\n",
            "f1score_true: 0.4172661870503597\n",
            "f1score_fake: 0.6988847583643123\n",
            "Binary_loss 0.6719921\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5196078431372549\n",
            "precision_true: 1.0\n",
            "precision_fake: 0.5184275184275184\n",
            "recall_true: 0.005076142131979695\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.010101010101010102\n",
            "f1score_fake: 0.6828478964401294\n",
            "Binary_loss 0.691698\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 8\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.7013888888888888\n",
            "precision_fake: 0.6363636363636364\n",
            "recall_true: 0.5126903553299492\n",
            "recall_fake: 0.7962085308056872\n",
            "f1score_true: 0.592375366568915\n",
            "f1score_fake: 0.7073684210526315\n",
            "Binary_loss 0.66795087\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5367647058823529\n",
            "precision_true: 0.6111111111111112\n",
            "precision_fake: 0.5295698924731183\n",
            "recall_true: 0.1116751269035533\n",
            "recall_fake: 0.933649289099526\n",
            "f1score_true: 0.1888412017167382\n",
            "f1score_fake: 0.6758147512864494\n",
            "Binary_loss 0.69057447\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 9\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.5865724381625441\n",
            "precision_fake: 0.752\n",
            "recall_true: 0.8426395939086294\n",
            "recall_fake: 0.44549763033175355\n",
            "f1score_true: 0.6916666666666667\n",
            "f1score_fake: 0.5595238095238095\n",
            "Binary_loss 0.6597742\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6078431372549019\n",
            "precision_true: 0.648\n",
            "precision_fake: 0.5901060070671378\n",
            "recall_true: 0.41116751269035534\n",
            "recall_fake: 0.7914691943127962\n",
            "f1score_true: 0.5031055900621118\n",
            "f1score_fake: 0.6761133603238867\n",
            "Binary_loss 0.6889137\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 10\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6053921568627451\n",
            "precision_true: 0.5588235294117647\n",
            "precision_fake: 0.7450980392156863\n",
            "recall_true: 0.868020304568528\n",
            "recall_fake: 0.36018957345971564\n",
            "f1score_true: 0.679920477137177\n",
            "f1score_fake: 0.4856230031948882\n",
            "Binary_loss 0.7043578\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6274509803921569\n",
            "precision_true: 0.6027397260273972\n",
            "precision_fake: 0.656084656084656\n",
            "recall_true: 0.6700507614213198\n",
            "recall_fake: 0.5876777251184834\n",
            "f1score_true: 0.6346153846153846\n",
            "f1score_fake: 0.6199999999999999\n",
            "Binary_loss 0.6864507\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6463262764632628\n",
            "precision_true: 0.613747954173486\n",
            "precision_fake: 0.75\n",
            "recall_true: 0.8865248226950354\n",
            "recall_fake: 0.37894736842105264\n",
            "f1score_true: 0.7253384912959381\n",
            "f1score_fake: 0.5034965034965034\n",
            "Binary_loss 0.6336186\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6376089663760897\n",
            "precision_true: 0.6578947368421053\n",
            "precision_fake: 0.6155844155844156\n",
            "recall_true: 0.6501182033096927\n",
            "recall_fake: 0.6236842105263158\n",
            "f1score_true: 0.6539833531510107\n",
            "f1score_fake: 0.6196078431372549\n",
            "Binary_loss 0.6847012\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 11\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6372549019607843\n",
            "precision_true: 0.6449704142011834\n",
            "precision_fake: 0.6317991631799164\n",
            "recall_true: 0.5532994923857868\n",
            "recall_fake: 0.7156398104265402\n",
            "f1score_true: 0.5956284153005464\n",
            "f1score_fake: 0.671111111111111\n",
            "Binary_loss 0.5971783\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6397058823529411\n",
            "precision_true: 0.6146788990825688\n",
            "precision_fake: 0.6684210526315789\n",
            "recall_true: 0.6802030456852792\n",
            "recall_fake: 0.6018957345971564\n",
            "f1score_true: 0.6457831325301204\n",
            "f1score_fake: 0.6334164588528678\n",
            "Binary_loss 0.68247956\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 12\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.6421052631578947\n",
            "precision_fake: 0.6559633027522935\n",
            "recall_true: 0.6192893401015228\n",
            "recall_fake: 0.6777251184834123\n",
            "f1score_true: 0.6304909560723513\n",
            "f1score_fake: 0.6666666666666666\n",
            "Binary_loss 0.59807456\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6530612244897959\n",
            "precision_fake: 0.6745283018867925\n",
            "recall_true: 0.649746192893401\n",
            "recall_fake: 0.6777251184834123\n",
            "f1score_true: 0.6513994910941475\n",
            "f1score_fake: 0.6761229314420804\n",
            "Binary_loss 0.67658406\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 13\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6435643564356436\n",
            "precision_fake: 0.6747572815533981\n",
            "recall_true: 0.6598984771573604\n",
            "recall_fake: 0.6587677725118484\n",
            "f1score_true: 0.6516290726817042\n",
            "f1score_fake: 0.6666666666666667\n",
            "Binary_loss 0.61069334\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6691176470588235\n",
            "precision_true: 0.6761363636363636\n",
            "precision_fake: 0.6637931034482759\n",
            "recall_true: 0.6040609137055838\n",
            "recall_fake: 0.7298578199052133\n",
            "f1score_true: 0.6380697050938338\n",
            "f1score_fake: 0.6952595936794582\n",
            "Binary_loss 0.66818416\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 14\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6348039215686274\n",
            "precision_true: 0.7181818181818181\n",
            "precision_fake: 0.6040268456375839\n",
            "recall_true: 0.4010152284263959\n",
            "recall_fake: 0.8530805687203792\n",
            "f1score_true: 0.5146579804560261\n",
            "f1score_fake: 0.7072691552062867\n",
            "Binary_loss 0.6684572\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.6832298136645962\n",
            "precision_fake: 0.6477732793522267\n",
            "recall_true: 0.5583756345177665\n",
            "recall_fake: 0.7582938388625592\n",
            "f1score_true: 0.6145251396648045\n",
            "f1score_fake: 0.6986899563318777\n",
            "Binary_loss 0.6565865\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 15\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6355140186915887\n",
            "precision_fake: 0.6855670103092784\n",
            "recall_true: 0.6903553299492385\n",
            "recall_fake: 0.6303317535545023\n",
            "f1score_true: 0.6618004866180048\n",
            "f1score_fake: 0.6567901234567901\n",
            "Binary_loss 0.8029082\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6851851851851852\n",
            "precision_fake: 0.6504065040650406\n",
            "recall_true: 0.5634517766497462\n",
            "recall_fake: 0.7582938388625592\n",
            "f1score_true: 0.6183844011142061\n",
            "f1score_fake: 0.7002188183807441\n",
            "Binary_loss 0.6427349\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.684931506849315\n",
            "precision_true: 0.7125\n",
            "precision_fake: 0.6575682382133995\n",
            "recall_true: 0.6737588652482269\n",
            "recall_fake: 0.6973684210526315\n",
            "f1score_true: 0.6925880923450789\n",
            "f1score_fake: 0.6768837803320562\n",
            "Binary_loss 0.6716726\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6612702366127023\n",
            "precision_true: 0.7267267267267268\n",
            "precision_fake: 0.6148936170212767\n",
            "recall_true: 0.5721040189125296\n",
            "recall_fake: 0.7605263157894737\n",
            "f1score_true: 0.6402116402116402\n",
            "f1score_fake: 0.68\n",
            "Binary_loss 0.6378683\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 16\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6271186440677966\n",
            "precision_fake: 0.7151162790697675\n",
            "recall_true: 0.751269035532995\n",
            "recall_fake: 0.5829383886255924\n",
            "f1score_true: 0.6836027713625866\n",
            "f1score_fake: 0.6422976501305483\n",
            "Binary_loss 0.7418598\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6964285714285714\n",
            "precision_fake: 0.6666666666666666\n",
            "recall_true: 0.5939086294416244\n",
            "recall_fake: 0.7582938388625592\n",
            "f1score_true: 0.6410958904109589\n",
            "f1score_fake: 0.7095343680709534\n",
            "Binary_loss 0.62681776\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 17\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.6509433962264151\n",
            "precision_fake: 0.6989795918367347\n",
            "recall_true: 0.700507614213198\n",
            "recall_fake: 0.6492890995260664\n",
            "f1score_true: 0.6748166259168703\n",
            "f1score_fake: 0.6732186732186732\n",
            "Binary_loss 0.82371384\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.686046511627907\n",
            "precision_fake: 0.6652542372881356\n",
            "recall_true: 0.5989847715736041\n",
            "recall_fake: 0.7440758293838863\n",
            "f1score_true: 0.6395663956639566\n",
            "f1score_fake: 0.7024608501118569\n",
            "Binary_loss 0.6099757\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 18\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6519607843137255\n",
            "precision_true: 0.6536312849162011\n",
            "precision_fake: 0.6506550218340611\n",
            "recall_true: 0.5939086294416244\n",
            "recall_fake: 0.7061611374407583\n",
            "f1score_true: 0.6223404255319148\n",
            "f1score_fake: 0.6772727272727272\n",
            "Binary_loss 0.7855597\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.6923076923076923\n",
            "precision_fake: 0.6652719665271967\n",
            "recall_true: 0.5939086294416244\n",
            "recall_fake: 0.7535545023696683\n",
            "f1score_true: 0.639344262295082\n",
            "f1score_fake: 0.7066666666666667\n",
            "Binary_loss 0.5968988\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 19\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.6234309623430963\n",
            "precision_fake: 0.7159763313609467\n",
            "recall_true: 0.7563451776649747\n",
            "recall_fake: 0.5734597156398105\n",
            "f1score_true: 0.6834862385321101\n",
            "f1score_fake: 0.6368421052631579\n",
            "Binary_loss 0.7877434\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6862745098039216\n",
            "precision_true: 0.7169811320754716\n",
            "precision_fake: 0.6666666666666666\n",
            "recall_true: 0.5786802030456852\n",
            "recall_fake: 0.7867298578199052\n",
            "f1score_true: 0.6404494382022471\n",
            "f1score_fake: 0.7217391304347825\n",
            "Binary_loss 0.592895\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 20\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6470588235294118\n",
            "precision_true: 0.6072874493927125\n",
            "precision_fake: 0.7080745341614907\n",
            "recall_true: 0.7614213197969543\n",
            "recall_fake: 0.5402843601895735\n",
            "f1score_true: 0.6756756756756755\n",
            "f1score_fake: 0.6129032258064516\n",
            "Binary_loss 0.84235203\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6813186813186813\n",
            "precision_fake: 0.6769911504424779\n",
            "recall_true: 0.6294416243654822\n",
            "recall_fake: 0.7251184834123223\n",
            "f1score_true: 0.6543535620052772\n",
            "f1score_fake: 0.7002288329519452\n",
            "Binary_loss 0.59335476\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.7073474470734745\n",
            "precision_true: 0.6934156378600823\n",
            "precision_fake: 0.7287066246056783\n",
            "recall_true: 0.7966903073286052\n",
            "recall_fake: 0.6078947368421053\n",
            "f1score_true: 0.7414741474147415\n",
            "f1score_fake: 0.6628407460545193\n",
            "Binary_loss 0.6915024\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.676214196762142\n",
            "precision_true: 0.7418397626112759\n",
            "precision_fake: 0.628755364806867\n",
            "recall_true: 0.5910165484633569\n",
            "recall_fake: 0.7710526315789473\n",
            "f1score_true: 0.6578947368421053\n",
            "f1score_fake: 0.6926713947990544\n",
            "Binary_loss 0.57268876\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 21\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6304347826086957\n",
            "precision_fake: 0.7078651685393258\n",
            "recall_true: 0.7360406091370558\n",
            "recall_fake: 0.5971563981042654\n",
            "f1score_true: 0.6791569086651054\n",
            "f1score_fake: 0.6478149100257069\n",
            "Binary_loss 0.873497\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6862745098039216\n",
            "precision_true: 0.6885245901639344\n",
            "precision_fake: 0.6844444444444444\n",
            "recall_true: 0.6395939086294417\n",
            "recall_fake: 0.7298578199052133\n",
            "f1score_true: 0.6631578947368421\n",
            "f1score_fake: 0.7064220183486238\n",
            "Binary_loss 0.5994899\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 22\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6293103448275862\n",
            "precision_fake: 0.7102272727272727\n",
            "recall_true: 0.7411167512690355\n",
            "recall_fake: 0.5924170616113744\n",
            "f1score_true: 0.6806526806526807\n",
            "f1score_fake: 0.6459948320413437\n",
            "Binary_loss 0.8711216\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6833333333333333\n",
            "precision_fake: 0.6754385964912281\n",
            "recall_true: 0.6243654822335025\n",
            "recall_fake: 0.7298578199052133\n",
            "f1score_true: 0.6525198938992043\n",
            "f1score_fake: 0.7015945330296128\n",
            "Binary_loss 0.6130046\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 23\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6401869158878505\n",
            "precision_fake: 0.6907216494845361\n",
            "recall_true: 0.6954314720812182\n",
            "recall_fake: 0.6350710900473934\n",
            "f1score_true: 0.6666666666666667\n",
            "f1score_fake: 0.6617283950617284\n",
            "Binary_loss 0.89783597\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.6810810810810811\n",
            "precision_fake: 0.6816143497757847\n",
            "recall_true: 0.6395939086294417\n",
            "recall_fake: 0.7203791469194313\n",
            "f1score_true: 0.6596858638743456\n",
            "f1score_fake: 0.7004608294930875\n",
            "Binary_loss 0.63858414\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 24\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.6683417085427136\n",
            "precision_fake: 0.69377990430622\n",
            "recall_true: 0.6751269035532995\n",
            "recall_fake: 0.6872037914691943\n",
            "f1score_true: 0.6717171717171717\n",
            "f1score_fake: 0.6904761904761905\n",
            "Binary_loss 0.87051135\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.6772486772486772\n",
            "precision_fake: 0.684931506849315\n",
            "recall_true: 0.649746192893401\n",
            "recall_fake: 0.7109004739336493\n",
            "f1score_true: 0.6632124352331605\n",
            "f1score_fake: 0.6976744186046511\n",
            "Binary_loss 0.6709794\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 25\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.6584158415841584\n",
            "precision_fake: 0.6893203883495146\n",
            "recall_true: 0.6751269035532995\n",
            "recall_fake: 0.6729857819905213\n",
            "f1score_true: 0.6666666666666666\n",
            "f1score_fake: 0.6810551558752997\n",
            "Binary_loss 0.93311936\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6838235294117647\n",
            "precision_true: 0.6789473684210526\n",
            "precision_fake: 0.6880733944954128\n",
            "recall_true: 0.6548223350253807\n",
            "recall_fake: 0.7109004739336493\n",
            "f1score_true: 0.6666666666666666\n",
            "f1score_fake: 0.6993006993006993\n",
            "Binary_loss 0.7107136\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6948941469489415\n",
            "precision_true: 0.7354497354497355\n",
            "precision_fake: 0.6588235294117647\n",
            "recall_true: 0.6572104018912529\n",
            "recall_fake: 0.7368421052631579\n",
            "f1score_true: 0.6941323345817728\n",
            "f1score_fake: 0.6956521739130435\n",
            "Binary_loss 0.80791926\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6861768368617683\n",
            "precision_true: 0.7408450704225352\n",
            "precision_fake: 0.6428571428571429\n",
            "recall_true: 0.6217494089834515\n",
            "recall_fake: 0.7578947368421053\n",
            "f1score_true: 0.6760925449871465\n",
            "f1score_fake: 0.6956521739130435\n",
            "Binary_loss 0.6281877\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 26\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6568627450980392\n",
            "precision_true: 0.6350710900473934\n",
            "precision_fake: 0.6802030456852792\n",
            "recall_true: 0.6802030456852792\n",
            "recall_fake: 0.6350710900473934\n",
            "f1score_true: 0.6568627450980392\n",
            "f1score_fake: 0.6568627450980392\n",
            "Binary_loss 0.96809775\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6838235294117647\n",
            "precision_true: 0.6770833333333334\n",
            "precision_fake: 0.6898148148148148\n",
            "recall_true: 0.6598984771573604\n",
            "recall_fake: 0.7061611374407583\n",
            "f1score_true: 0.6683804627249357\n",
            "f1score_fake: 0.6978922716627635\n",
            "Binary_loss 0.74693733\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 27\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.642512077294686\n",
            "precision_fake: 0.681592039800995\n",
            "recall_true: 0.6751269035532995\n",
            "recall_fake: 0.6492890995260664\n",
            "f1score_true: 0.6584158415841583\n",
            "f1score_fake: 0.6650485436893204\n",
            "Binary_loss 0.94478625\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.675392670157068\n",
            "precision_fake: 0.6866359447004609\n",
            "recall_true: 0.6548223350253807\n",
            "recall_fake: 0.7061611374407583\n",
            "f1score_true: 0.6649484536082474\n",
            "f1score_fake: 0.6962616822429907\n",
            "Binary_loss 0.7779087\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 28\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6323529411764706\n",
            "precision_true: 0.592156862745098\n",
            "precision_fake: 0.6993464052287581\n",
            "recall_true: 0.766497461928934\n",
            "recall_fake: 0.5071090047393365\n",
            "f1score_true: 0.6681415929203539\n",
            "f1score_fake: 0.5879120879120879\n",
            "Binary_loss 1.2232227\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6862745098039216\n",
            "precision_true: 0.676923076923077\n",
            "precision_fake: 0.6948356807511737\n",
            "recall_true: 0.6700507614213198\n",
            "recall_fake: 0.7014218009478673\n",
            "f1score_true: 0.6734693877551021\n",
            "f1score_fake: 0.6981132075471699\n",
            "Binary_loss 0.813208\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 29\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6642156862745098\n",
            "precision_true: 0.6875\n",
            "precision_fake: 0.6491935483870968\n",
            "recall_true: 0.5583756345177665\n",
            "recall_fake: 0.7630331753554502\n",
            "f1score_true: 0.6162464985994397\n",
            "f1score_fake: 0.7015250544662309\n",
            "Binary_loss 1.0073193\n",
            "*******TEACHER*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6683673469387755\n",
            "precision_fake: 0.6886792452830188\n",
            "recall_true: 0.6649746192893401\n",
            "recall_fake: 0.6919431279620853\n",
            "f1score_true: 0.6666666666666666\n",
            "f1score_fake: 0.6903073286052009\n",
            "Binary_loss 0.8489001\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 30\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6793478260869565\n",
            "precision_fake: 0.6785714285714286\n",
            "recall_true: 0.6345177664974619\n",
            "recall_fake: 0.7203791469194313\n",
            "f1score_true: 0.6561679790026247\n",
            "f1score_fake: 0.6988505747126437\n",
            "Binary_loss 1.0076087\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.642512077294686\n",
            "precision_fake: 0.681592039800995\n",
            "recall_true: 0.6751269035532995\n",
            "recall_fake: 0.6492890995260664\n",
            "f1score_true: 0.6584158415841583\n",
            "f1score_fake: 0.6650485436893204\n",
            "Binary_loss 0.88061297\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6712328767123288\n",
            "precision_true: 0.729106628242075\n",
            "precision_fake: 0.6271929824561403\n",
            "recall_true: 0.5981087470449172\n",
            "recall_fake: 0.7526315789473684\n",
            "f1score_true: 0.6571428571428571\n",
            "f1score_fake: 0.6842105263157895\n",
            "Binary_loss 0.9082744\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.6861768368617683\n",
            "precision_true: 0.7255936675461742\n",
            "precision_fake: 0.6509433962264151\n",
            "recall_true: 0.6501182033096927\n",
            "recall_fake: 0.7263157894736842\n",
            "f1score_true: 0.685785536159601\n",
            "f1score_fake: 0.6865671641791045\n",
            "Binary_loss 0.7424783\n",
            "-----------------------------------------------------------------\n",
            "train Data_Size: (1630, 100)\n",
            "test Data_Size: (803, 100)\n",
            "Train Label count: True, Fake 858 772\n",
            "Test Label count : True, Fake 401 402\n",
            "Train Mean teacher Model...\n",
            "20/20 [==============================] - 9s 433ms/step - loss: 0.6930 - accuracy: 0.4943\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 1\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5245098039215687\n",
            "precision_true: 0.5511811023622047\n",
            "precision_fake: 0.4805194805194805\n",
            "recall_true: 0.6363636363636364\n",
            "recall_fake: 0.39361702127659576\n",
            "f1score_true: 0.5907172995780591\n",
            "f1score_fake: 0.43274853801169594\n",
            "Binary_loss 0.6909532\n",
            "*******TEACHER*************\n",
            "accuracy: 0.46078431372549017\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.46078431372549017\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6308724832214765\n",
            "Binary_loss 0.69281983\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 2\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5465686274509803\n",
            "precision_true: 0.5614035087719298\n",
            "precision_fake: 0.5121951219512195\n",
            "recall_true: 0.7272727272727273\n",
            "recall_fake: 0.3351063829787234\n",
            "f1score_true: 0.6336633663366337\n",
            "f1score_fake: 0.40514469453376206\n",
            "Binary_loss 0.6889569\n",
            "*******TEACHER*************\n",
            "accuracy: 0.46078431372549017\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.46078431372549017\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6308724832214765\n",
            "Binary_loss 0.693132\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 3\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5686274509803921\n",
            "precision_true: 0.5748299319727891\n",
            "precision_fake: 0.5526315789473685\n",
            "recall_true: 0.7681818181818182\n",
            "recall_fake: 0.3351063829787234\n",
            "f1score_true: 0.6575875486381323\n",
            "f1score_fake: 0.41721854304635764\n",
            "Binary_loss 0.68744254\n",
            "*******TEACHER*************\n",
            "accuracy: 0.46078431372549017\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.46078431372549017\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6308724832214765\n",
            "Binary_loss 0.6930943\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 4\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5808823529411765\n",
            "precision_true: 0.5819397993311036\n",
            "precision_fake: 0.5779816513761468\n",
            "recall_true: 0.7909090909090909\n",
            "recall_fake: 0.3351063829787234\n",
            "f1score_true: 0.6705202312138728\n",
            "f1score_fake: 0.42424242424242425\n",
            "Binary_loss 0.68557054\n",
            "*******TEACHER*************\n",
            "accuracy: 0.46078431372549017\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.46078431372549017\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6308724832214765\n",
            "Binary_loss 0.6928078\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 5\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.5808823529411765\n",
            "precision_true: 0.5819397993311036\n",
            "precision_fake: 0.5779816513761468\n",
            "recall_true: 0.7909090909090909\n",
            "recall_fake: 0.3351063829787234\n",
            "f1score_true: 0.6705202312138728\n",
            "f1score_fake: 0.42424242424242425\n",
            "Binary_loss 0.68274736\n",
            "*******TEACHER*************\n",
            "accuracy: 0.46078431372549017\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.46078431372549017\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6308724832214765\n",
            "Binary_loss 0.69230604\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 6\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6102941176470589\n",
            "precision_true: 0.6205533596837944\n",
            "precision_fake: 0.5935483870967742\n",
            "recall_true: 0.7136363636363636\n",
            "recall_fake: 0.48936170212765956\n",
            "f1score_true: 0.6638477801268499\n",
            "f1score_fake: 0.5364431486880467\n",
            "Binary_loss 0.67225945\n",
            "*******TEACHER*************\n",
            "accuracy: 0.46078431372549017\n",
            "precision_true: 0.0\n",
            "precision_fake: 0.46078431372549017\n",
            "recall_true: 0.0\n",
            "recall_fake: 1.0\n",
            "f1score_true: 0.0\n",
            "f1score_fake: 0.6308724832214765\n",
            "Binary_loss 0.6915395\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 7\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6495098039215687\n",
            "precision_true: 0.6191950464396285\n",
            "precision_fake: 0.7647058823529411\n",
            "recall_true: 0.9090909090909091\n",
            "recall_fake: 0.34574468085106386\n",
            "f1score_true: 0.7366482504604052\n",
            "f1score_fake: 0.4761904761904762\n",
            "Binary_loss 0.6576462\n",
            "*******TEACHER*************\n",
            "accuracy: 0.553921568627451\n",
            "precision_true: 0.7375\n",
            "precision_fake: 0.5091463414634146\n",
            "recall_true: 0.2681818181818182\n",
            "recall_fake: 0.8882978723404256\n",
            "f1score_true: 0.3933333333333333\n",
            "f1score_fake: 0.6472868217054264\n",
            "Binary_loss 0.6903438\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 8\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6446078431372549\n",
            "precision_true: 0.6175548589341693\n",
            "precision_fake: 0.7415730337078652\n",
            "recall_true: 0.8954545454545455\n",
            "recall_fake: 0.35106382978723405\n",
            "f1score_true: 0.7309833024118739\n",
            "f1score_fake: 0.476534296028881\n",
            "Binary_loss 0.62554306\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5661764705882353\n",
            "precision_true: 0.6059113300492611\n",
            "precision_fake: 0.526829268292683\n",
            "recall_true: 0.5590909090909091\n",
            "recall_fake: 0.574468085106383\n",
            "f1score_true: 0.5815602836879433\n",
            "f1score_fake: 0.549618320610687\n",
            "Binary_loss 0.6886235\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 9\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.777027027027027\n",
            "precision_fake: 0.5961538461538461\n",
            "recall_true: 0.5227272727272727\n",
            "recall_fake: 0.824468085106383\n",
            "f1score_true: 0.625\n",
            "f1score_fake: 0.6919642857142858\n",
            "Binary_loss 0.60408247\n",
            "*******TEACHER*************\n",
            "accuracy: 0.5857843137254902\n",
            "precision_true: 0.6058091286307054\n",
            "precision_fake: 0.5568862275449101\n",
            "recall_true: 0.6636363636363637\n",
            "recall_fake: 0.4946808510638298\n",
            "f1score_true: 0.6334056399132321\n",
            "f1score_fake: 0.5239436619718311\n",
            "Binary_loss 0.6860642\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 10\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.6187683284457478\n",
            "precision_fake: 0.8656716417910447\n",
            "recall_true: 0.9590909090909091\n",
            "recall_fake: 0.30851063829787234\n",
            "f1score_true: 0.7522281639928698\n",
            "f1score_fake: 0.4549019607843137\n",
            "Binary_loss 0.62980616\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6274509803921569\n",
            "precision_true: 0.6307692307692307\n",
            "precision_fake: 0.6216216216216216\n",
            "recall_true: 0.7454545454545455\n",
            "recall_fake: 0.48936170212765956\n",
            "f1score_true: 0.6833333333333332\n",
            "f1score_fake: 0.5476190476190476\n",
            "Binary_loss 0.68233174\n",
            "---------------------------STUDENT--------------------------\n",
            "accuracy: 0.6251556662515566\n",
            "precision_true: 0.5722543352601156\n",
            "precision_fake: 0.954954954954955\n",
            "recall_true: 0.9875311720698254\n",
            "recall_fake: 0.263681592039801\n",
            "f1score_true: 0.7246111619396157\n",
            "f1score_fake: 0.41325536062378165\n",
            "Binary_loss 0.62072957\n",
            "-----------------------------------------------------------------\n",
            "---------------------------TEACHER---------------------------------\n",
            "accuracy: 0.5990037359900373\n",
            "precision_true: 0.5785288270377733\n",
            "precision_fake: 0.6333333333333333\n",
            "recall_true: 0.7256857855361596\n",
            "recall_fake: 0.472636815920398\n",
            "f1score_true: 0.6438053097345132\n",
            "f1score_fake: 0.5413105413105412\n",
            "Binary_loss 0.6856563\n",
            "-----------------------------------------------------------------\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 11\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6666666666666666\n",
            "precision_true: 0.6280487804878049\n",
            "precision_fake: 0.825\n",
            "recall_true: 0.9363636363636364\n",
            "recall_fake: 0.35106382978723405\n",
            "f1score_true: 0.7518248175182483\n",
            "f1score_fake: 0.49253731343283574\n",
            "Binary_loss 0.60814875\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6617647058823529\n",
            "precision_true: 0.6541353383458647\n",
            "precision_fake: 0.676056338028169\n",
            "recall_true: 0.7909090909090909\n",
            "recall_fake: 0.5106382978723404\n",
            "f1score_true: 0.7160493827160495\n",
            "f1score_fake: 0.5818181818181819\n",
            "Binary_loss 0.67707527\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 12\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6715686274509803\n",
            "precision_true: 0.75\n",
            "precision_fake: 0.614406779661017\n",
            "recall_true: 0.5863636363636363\n",
            "recall_fake: 0.7712765957446809\n",
            "f1score_true: 0.6581632653061223\n",
            "f1score_fake: 0.6839622641509434\n",
            "Binary_loss 0.60338104\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6764705882352942\n",
            "precision_true: 0.6705426356589147\n",
            "precision_fake: 0.6866666666666666\n",
            "recall_true: 0.7863636363636364\n",
            "recall_fake: 0.5478723404255319\n",
            "f1score_true: 0.7238493723849372\n",
            "f1score_fake: 0.6094674556213017\n",
            "Binary_loss 0.66949314\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 13\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.678921568627451\n",
            "precision_true: 0.6960352422907489\n",
            "precision_fake: 0.6574585635359116\n",
            "recall_true: 0.7181818181818181\n",
            "recall_fake: 0.6329787234042553\n",
            "f1score_true: 0.7069351230425056\n",
            "f1score_fake: 0.6449864498644986\n",
            "Binary_loss 0.6298613\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6740196078431373\n",
            "precision_true: 0.6641509433962264\n",
            "precision_fake: 0.6923076923076923\n",
            "recall_true: 0.8\n",
            "recall_fake: 0.526595744680851\n",
            "f1score_true: 0.7257731958762886\n",
            "f1score_fake: 0.5981873111782477\n",
            "Binary_loss 0.65859425\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 14\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6838235294117647\n",
            "precision_true: 0.7177033492822966\n",
            "precision_fake: 0.6482412060301508\n",
            "recall_true: 0.6818181818181818\n",
            "recall_fake: 0.6861702127659575\n",
            "f1score_true: 0.6993006993006994\n",
            "f1score_fake: 0.6666666666666666\n",
            "Binary_loss 0.61012846\n",
            "*******TEACHER*************\n",
            "accuracy: 0.6813725490196079\n",
            "precision_true: 0.6691729323308271\n",
            "precision_fake: 0.704225352112676\n",
            "recall_true: 0.8090909090909091\n",
            "recall_fake: 0.5319148936170213\n",
            "f1score_true: 0.7325102880658436\n",
            "f1score_fake: 0.6060606060606061\n",
            "Binary_loss 0.6441191\n",
            "* * * * * * * * * * * * * * * * *\n",
            "Start of epoch 15\n",
            "* * * * * * * * * * * * * * * * *\n",
            "0.99\n",
            "*******STUDENT*************\n",
            "accuracy: 0.6593137254901961\n",
            "precision_true: 0.7425149700598802\n",
            "precision_fake: 0.6016597510373444\n",
            "recall_true: 0.5636363636363636\n",
            "recall_fake: 0.7712765957446809\n",
            "f1score_true: 0.6408268733850129\n",
            "f1score_fake: 0.675990675990676\n",
            "Binary_loss 0.67802835\n",
            "*******TEACHER*************\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}